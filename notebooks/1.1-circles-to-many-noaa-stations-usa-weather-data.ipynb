{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning circles to weather stations\n",
    "### Purpose\n",
    "Using a custom table created from uploading the CSV to Big Query (this table is called `cleaned_bird_counts_gstorage`) a join is done with the view that contains the flatten data.\n",
    "\n",
    "### Author: \n",
    "Francisco Vannini\n",
    "### Date: \n",
    "2020-04-02\n",
    "### Update Date: \n",
    "2020-04-02\n",
    "\n",
    "### Inputs\n",
    "<ol>\n",
    "<li> Google credential auth JSON </li>\n",
    "<li> noaa_from_1900_to_present view in BQ</li>\n",
    "<li> flatten_noaa_from_1900_to_present in BQ</li>\n",
    "<li> cleaned_bird_count data</li>\n",
    "</ol>\n",
    "\n",
    "### Output Files\n",
    "This notebook produces <strong>1.1-circles-to-many-noaa-stations-usa-weather-data-[data_this_process_was_run].csv.gzip</strong>. This data contains non-empty weather measurements for the NOAA stations that are in close proximity (using geohashes) of our CDC bird count. \n",
    "\n",
    "## Steps or Proceedures in the notebook\n",
    "This notebook creates a query that interlaces the CDC bird count data, matches it with NOAA stations in close proximity with this station and then extracts the NOAA station weather measurements pertinenet to the dates. After the data is extracted the rows that have a NULL value of \"temp_min\" are pruned AND only USA weather measurements included.\n",
    "\n",
    "## Where the Data will Be Saved \n",
    "This script produces data at the level where this notebook is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (0.24.0)\n",
      "Requirement already satisfied: google-cloud-core<0.25dev,>=0.24.0 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-bigquery) (0.24.1)\n",
      "Requirement already satisfied: google-auth<2.0.0dev,>=0.4.0 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (1.13.1)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.3.4 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (1.51.0)\n",
      "Requirement already satisfied: six in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (1.14.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (0.0.3)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (3.11.3)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (0.17.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (46.1.3)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/rcdebaca/.pyenv/versions/3.7.1/envs/funhacks371/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.25dev,>=0.24.0->google-cloud-bigquery) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery==0.24.0\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up the Enviroment \n",
    "\n",
    "# The path to your json credentials file. Replace with your corresponding file.\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"your_path_to_google_auth_keys.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../apicred/BirdProject-2020-d9b935674747.json\"\n",
    "\n",
    "# Used to classify the name \n",
    "time_now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "client = bigquery.Client()\n",
    "project = 'birdproject-2020'\n",
    "source_dataset_id = 'audubon_cdc'\n",
    "# source_table_id = 'us_states'\n",
    "shared_dataset_ref = client.dataset(source_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Most Recent Data File \n",
    "THIS IS NOT REQUIRED -- But It is good practice to confirm it is there and can be read correctly. \n",
    "The next section will load the data as part of the upload to bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL File Paths should be declared at the TOP of the notebook\n",
    "PATH_TO_CLEAN_CBC_DATA = \"../data/Cloud_Data/1.0-rec-initial-data-cleaning.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcdebaca/.pyenv/versions/funhacks371/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(PATH_TO_CLEAN_CBC_DATA, encoding = \"ISO-8859-1\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>max_snow_metric</th>\n",
       "      <th>max_snow_imperial</th>\n",
       "      <th>min_temp_imperial</th>\n",
       "      <th>max_temp_imperial</th>\n",
       "      <th>min_temp_metric</th>\n",
       "      <th>max_temp_metric</th>\n",
       "      <th>min_wind_metric</th>\n",
       "      <th>max_wind_metric</th>\n",
       "      <th>min_wind_imperial</th>\n",
       "      <th>max_wind_imperial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Pacific Grove</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>36.616700</td>\n",
       "      <td>-121.916700</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Pueblo</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>38.175251</td>\n",
       "      <td>-104.519575</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>US-CT</td>\n",
       "      <td>41.671800</td>\n",
       "      <td>-72.949500</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Norwalk</td>\n",
       "      <td>US-CT</td>\n",
       "      <td>41.116700</td>\n",
       "      <td>-73.400000</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Glen Ellyn</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>41.883300</td>\n",
       "      <td>-88.066700</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    circle_name country_state        lat         lon  count_year  \\\n",
       "0           2  Pacific Grove         US-CA  36.616700 -121.916700        1901   \n",
       "1           3         Pueblo         US-CO  38.175251 -104.519575        1901   \n",
       "2           4        Bristol         US-CT  41.671800  -72.949500        1901   \n",
       "3           5        Norwalk         US-CT  41.116700  -73.400000        1901   \n",
       "4           6     Glen Ellyn         US-IL  41.883300  -88.066700        1901   \n",
       "\n",
       "  count_date  n_field_counters  n_feeder_counters  min_field_parties  ...  \\\n",
       "0   12/25/00               1.0                NaN                NaN  ...   \n",
       "1   12/25/00               1.0                NaN                NaN  ...   \n",
       "2   12/25/00               2.0                NaN                NaN  ...   \n",
       "3   12/25/00               1.0                NaN                NaN  ...   \n",
       "4   12/25/00               1.0                NaN                NaN  ...   \n",
       "\n",
       "   max_snow_metric  max_snow_imperial  min_temp_imperial  max_temp_imperial  \\\n",
       "0              NaN                NaN                NaN                NaN   \n",
       "1              NaN                NaN                NaN                NaN   \n",
       "2              NaN                NaN                NaN                NaN   \n",
       "3              NaN                NaN                NaN                NaN   \n",
       "4              NaN                NaN                NaN                NaN   \n",
       "\n",
       "   min_temp_metric  max_temp_metric min_wind_metric  max_wind_metric  \\\n",
       "0              NaN              NaN             NaN              NaN   \n",
       "1              NaN              NaN             NaN              NaN   \n",
       "2              NaN              NaN             NaN              NaN   \n",
       "3              NaN              NaN             NaN              NaN   \n",
       "4              NaN              NaN             NaN              NaN   \n",
       "\n",
       "   min_wind_imperial  max_wind_imperial  \n",
       "0                NaN                NaN  \n",
       "1                NaN                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push this data up to bigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birdproject-2020.audubon_cdc.rec_initial_data_cleaning\n"
     ]
    }
   ],
   "source": [
    "# Prep creating a Table \n",
    "# table_id = \"your-project.your_dataset.your_table_name\"\n",
    "table_id = project + \".\"+ source_dataset_id + \".\" + \"rec_initial_data_cleaning\"\n",
    "\n",
    "print(table_id)             \n",
    "\n",
    "# Create the Schema, and by that i mean DONT create a shcema cuz biqQuery does a pretty good job \n",
    "schema = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'project'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-68dd5074c03b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create the BigQuery Table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make an API request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m print(\n",
      "\u001b[0;32m~/.pyenv/versions/funhacks371/lib/python3.7/site-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, table_ref, schema)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"Update the partitioning type of the table\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpartitioning\u001b[0m \u001b[0mtype\u001b[0m \u001b[0monly\u001b[0m \u001b[0;34m\"DAY\"\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcurrently\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \"\"\"\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'project'"
     ]
    }
   ],
   "source": [
    "# NOTE: This ran originally, but then started presenting with the error:\n",
    "#'AttributeError: 'str' object has no attribute 'project''\n",
    "# If that happens you can create the table manually in bigQuery (defeats the purpose of automation,\n",
    "# but if it fits it ships)\n",
    "\n",
    "# Create the BigQuery Table \n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)  # Make an API request.\n",
    "print(\n",
    "    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send the File up to the Cloud\n",
    "\n",
    "dataset_ref = client.dataset(source_dataset_id)\n",
    "table_ref = dataset_ref.table(\"rec_initial_data_cleaning\")\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.field_delimiter='\\t' \n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(PATH_TO_CLEAN_CBC_DATA, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, source_dataset_id, table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Query and Submit it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "# WITH circles_hash as (SELECT x.*, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 4) as geohash_circle, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 7) as circle_id\n",
    "\n",
    "# FROM `{project}.audubon_cdc.rec_initial_data_cleaning` x),\n",
    "\n",
    "# stations_hash as (SELECT y.*, ST_GEOHASH(ST_GEOGPOINT(y.longitude,y.latitude),4) as geohash_station FROM `bigquery-public-data`.ghcn_d.ghcnd_stations y),\n",
    "\n",
    "# circle_with_matched_stations as (SELECT * FROM circles_hash x INNER JOIN stations_hash y ON x.geohash_circle = y.geohash_station)\n",
    "\n",
    "# SELECT x.*, y.temp_min_value,y.temp_max_value,y.precipitation_value,y.temp_avg,y.snow,y.snwd\n",
    "\n",
    "# FROM circle_with_matched_stations x\n",
    "# LEFT JOIN `{project}.audubon_cdc.flatten_noaa_from_1900_to_present` y ON x.id = y.id AND x.count_date = y.date\n",
    "\n",
    "# ORDER BY circle_id DESC,count_date ASC \"\"\"\n",
    "\n",
    "# # Queries BigQuery public data set and creates a new dataframe object\n",
    "# df_circles_to_stations_weather_data = client.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH circles_hash as (SELECT x.*, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 4) as geohash_circle, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 7) as circle_id\n",
    "\n",
    "FROM `{project}.audubon_cdc.rec_initial_data_cleaning` x),\n",
    "\n",
    "stations_hash as (SELECT y.*, ST_GEOHASH(ST_GEOGPOINT(y.longitude,y.latitude),4) as geohash_station FROM `bigquery-public-data`.ghcn_d.ghcnd_stations y),\n",
    "\n",
    "circle_with_matched_stations as (SELECT * FROM circles_hash x INNER JOIN stations_hash y ON x.geohash_circle = y.geohash_station)\n",
    "\n",
    "SELECT x.*, y.temp_min_value,y.temp_max_value,y.precipitation_value,y.temp_avg,y.snow,y.snwd\n",
    "\n",
    "FROM circle_with_matched_stations x\n",
    "LEFT JOIN `{project}.audubon_cdc.flatten_noaa_from_1900_to_present` y ON x.id = y.id AND x.count_date = y.date\n",
    "\n",
    "ORDER BY circle_id DESC,count_date ASC \"\"\"\n",
    "\n",
    "# Queries BigQuery public data set and creates a new dataframe object\n",
    "df_circles_to_stations_weather_data = client.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles_to_stations_weather_data = df_circles_to_stations_weather_data.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1047595, 66)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_circles_to_stations_weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving stations in csv COMPRESSED IN GZIP!!!\n",
    "df_circles_to_stations_weather_data.to_csv(r'1.1-circles_to_many_stations_usa_weather_data_' + str(time_now) +  '.csv', compression = \"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 records\n",
    "Showing the top 5 records of the data extracted to the query above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int64_field_0</th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>gsn_flag</th>\n",
       "      <th>hcn_crn_flag</th>\n",
       "      <th>wmoid</th>\n",
       "      <th>geohash_station</th>\n",
       "      <th>temp_min_value</th>\n",
       "      <th>temp_max_value</th>\n",
       "      <th>precipitation_value</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28806</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1977</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28806</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1977</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30036</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1978</td>\n",
       "      <td>1977-12-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30036</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1978</td>\n",
       "      <td>1977-12-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31321</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1979</td>\n",
       "      <td>1978-12-30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   int64_field_0      circle_name country_state        lat         lon  \\\n",
       "0          28806  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "1          28806  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "2          30036  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "3          30036  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "4          31321  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "\n",
       "   count_year  count_date  n_field_counters n_feeder_counters  \\\n",
       "0        1977  1977-01-01               4.0              None   \n",
       "1        1977  1977-01-01               4.0              None   \n",
       "2        1978  1977-12-29               5.0              None   \n",
       "3        1978  1977-12-29               5.0              None   \n",
       "4        1979  1978-12-30               2.0              None   \n",
       "\n",
       "  min_field_parties  ... gsn_flag hcn_crn_flag wmoid geohash_station  \\\n",
       "0              None  ...                         NaN            zcpk   \n",
       "1              None  ...                         NaN            zcpk   \n",
       "2              None  ...                         NaN            zcpk   \n",
       "3              None  ...                         NaN            zcpk   \n",
       "4              None  ...                         NaN            zcpk   \n",
       "\n",
       "  temp_min_value temp_max_value precipitation_value temp_avg snow snwd  \n",
       "0            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "1            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "2            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "3            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "4            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_circles_to_stations_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on dataset\n",
    "How many records are empty for the various temperature measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many rows in dataset with missing vals:  1047595\n",
      "Missing min temperature: 981842\n",
      "Missing max temperature: 981834\n",
      "Missing avg temperature: 1039022\n",
      "Missing snow temperature: 955619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "record_count = len(df_circles_to_stations_weather_data.index)\n",
    "print('How many rows in dataset with missing vals: ', record_count)\n",
    "\n",
    "temp_min_nas = df_circles_to_stations_weather_data.temp_min_value.isna().sum()\n",
    "print(\"Missing min temperature: \" + str(temp_min_nas))\n",
    "\n",
    "temp_max_nas = df_circles_to_stations_weather_data.temp_max_value.isna().sum()\n",
    "print(\"Missing max temperature: \" + str(temp_max_nas))\n",
    "\n",
    "temp_avg_nas = df_circles_to_stations_weather_data.temp_avg.isna().sum()\n",
    "print(\"Missing avg temperature: \" + str(temp_avg_nas))\n",
    "\n",
    "snow = df_circles_to_stations_weather_data.snow.isna().sum()\n",
    "print(\"Missing snow temperature: \" + str(snow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty min/max temperature\n",
    "Create new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int64_field_0</th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>gsn_flag</th>\n",
       "      <th>hcn_crn_flag</th>\n",
       "      <th>wmoid</th>\n",
       "      <th>geohash_station</th>\n",
       "      <th>temp_min_value</th>\n",
       "      <th>temp_max_value</th>\n",
       "      <th>precipitation_value</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32617</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1980</td>\n",
       "      <td>1979-12-18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>90930</td>\n",
       "      <td>Caribou</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>46.912573</td>\n",
       "      <td>-67.947428</td>\n",
       "      <td>2012</td>\n",
       "      <td>2011-12-28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>72712.0</td>\n",
       "      <td>f2rd</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>93245</td>\n",
       "      <td>Caribou</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>46.912573</td>\n",
       "      <td>-67.947428</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>72712.0</td>\n",
       "      <td>f2rd</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>95653</td>\n",
       "      <td>Caribou</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>46.912573</td>\n",
       "      <td>-67.947428</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>72712.0</td>\n",
       "      <td>f2rd</td>\n",
       "      <td>-282.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>98110</td>\n",
       "      <td>Caribou</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>46.912573</td>\n",
       "      <td>-67.947428</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014-12-14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>72712.0</td>\n",
       "      <td>f2rd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    int64_field_0      circle_name country_state        lat         lon  \\\n",
       "7           32617  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "27          90930          Caribou         US-ME  46.912573  -67.947428   \n",
       "30          93245          Caribou         US-ME  46.912573  -67.947428   \n",
       "32          95653          Caribou         US-ME  46.912573  -67.947428   \n",
       "33          98110          Caribou         US-ME  46.912573  -67.947428   \n",
       "\n",
       "    count_year  count_date  n_field_counters n_feeder_counters  \\\n",
       "7         1980  1979-12-18               4.0              None   \n",
       "27        2012  2011-12-28              10.0               3.0   \n",
       "30        2013  2012-12-29              10.0               4.0   \n",
       "32        2014  2014-01-01               7.0               5.0   \n",
       "33        2015  2014-12-14              10.0               6.0   \n",
       "\n",
       "   min_field_parties  ... gsn_flag hcn_crn_flag    wmoid geohash_station  \\\n",
       "7               None  ...                            NaN            zcpk   \n",
       "27               1.0  ...      GSN               72712.0            f2rd   \n",
       "30               2.0  ...      GSN               72712.0            f2rd   \n",
       "32               1.0  ...      GSN               72712.0            f2rd   \n",
       "33               1.0  ...      GSN               72712.0            f2rd   \n",
       "\n",
       "   temp_min_value temp_max_value precipitation_value temp_avg snow   snwd  \n",
       "7           -17.0           17.0                 5.0      NaN  3.0    0.0  \n",
       "27          -83.0           78.0                71.0      NaN  8.0   25.0  \n",
       "30         -139.0          -61.0                 0.0      NaN  0.0  229.0  \n",
       "32         -282.0         -155.0                 0.0      NaN  3.0  460.0  \n",
       "33            0.0           22.0                 0.0      NaN  0.0  150.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref=df_circles_to_stations_weather_data.temp_min_value\n",
    "paired_data=df_circles_to_stations_weather_data[ref.notna()]\n",
    "paired_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65753, 66)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records in this data set is:  65753\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of records in this data set is: \", len(paired_data.circle_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Data in the USA\n",
    "Create new data frame for stations only for stations located in the USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows station usa weather data:  65539\n"
     ]
    }
   ],
   "source": [
    "paired_data_usa = paired_data[paired_data.id.str.slice(stop=2)==\"US\"]\n",
    "print(\"The number of rows station usa weather data: \", len(paired_data_usa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving stations in csv COMPRESSED IN GZIP!!!\n",
    "paired_data_usa.to_csv(r'1.1-circles_to_many_stations_usa_weather_data_' + str(time_now) +  '.csv', compression = \"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

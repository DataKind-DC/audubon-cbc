{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning circles to weather stations\n",
    "### Purpose\n",
    "Using a custom table created from uploading the CSV to Big Query (this table is called `cleaned_bird_counts_gstorage`) a join is done with the view that contains the flatten data.\n",
    "\n",
    "### Author: \n",
    "Francisco Vannini\n",
    "### Date: \n",
    "2020-04-02\n",
    "### Update Date: \n",
    "2020-04-02\n",
    "\n",
    "### Inputs\n",
    "<ol>\n",
    "<li> Google credential auth JSON </li>\n",
    "<li> noaa_from_1900_to_present view in BQ</li>\n",
    "<li> flatten_noaa_from_1900_to_present in BQ</li>\n",
    "<li> cleaned_bird_count data</li>\n",
    "</ol>\n",
    "\n",
    "### Output Files\n",
    "This notebook produces <strong>1.1-circles-to-many-noaa-stations-usa-weather-data-[data_this_process_was_run].csv.gzip</strong>. This data contains non-empty weather measurements for the NOAA stations that are in close proximity (using geohashes) of our CDC bird count. \n",
    "\n",
    "## Steps or Proceedures in the notebook\n",
    "This notebook creates a query that interlaces the CDC bird count data, matches it with NOAA stations in close proximity with this station and then extracts the NOAA station weather measurements pertinenet to the dates. After the data is extracted the rows that have a NULL value of \"temp_min\" are pruned AND only USA weather measurements included.\n",
    "\n",
    "To prep for the query, it loads in cleaned data and uploads it to BiqQuery so the query has access to it.\n",
    "\n",
    "## Where the Data will Be Saved \n",
    "This script produces data at the level where this notebook is located.\n",
    "\n",
    "## NOTES on Running This Notebook\n",
    "If you are getting errors from the biquery modual that seem weird, Try complely stoping your notebook kernal and restarting it. There are some werid errors that can happen when running BigQuery from a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "# Version .24.0\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up the Enviroment \n",
    "\n",
    "# The path to your json credentials file. Replace with your corresponding file.\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"your_path_to_google_auth_keys.json\"\n",
    "\n",
    "# Used to classify the name \n",
    "time_now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "client = bigquery.Client()\n",
    "project = 'birdproject-2020'\n",
    "source_dataset_id = 'audubon_cdc'\n",
    "# source_table_id = 'us_states'\n",
    "shared_dataset_ref = client.dataset(source_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.client.Client at 0x104833be0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Most Recent Data File \n",
    "THIS IS NOT REQUIRED -- But It is good practice to confirm it is there and can be read correctly. \n",
    "The next section will load the data as part of the upload to bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL File Paths should be declared at the TOP of the notebook\n",
    "PATH_TO_CLEAN_CBC_DATA = \"../data/Cloud_Data/1.0-rec-initial-data-cleaning.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcdebaca/.pyenv/versions/funhacks371/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(PATH_TO_CLEAN_CBC_DATA, encoding = \"ISO-8859-1\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>max_snow_metric</th>\n",
       "      <th>max_snow_imperial</th>\n",
       "      <th>min_temp_imperial</th>\n",
       "      <th>max_temp_imperial</th>\n",
       "      <th>min_temp_metric</th>\n",
       "      <th>max_temp_metric</th>\n",
       "      <th>min_wind_metric</th>\n",
       "      <th>max_wind_metric</th>\n",
       "      <th>min_wind_imperial</th>\n",
       "      <th>max_wind_imperial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Pacific Grove</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>36.616700</td>\n",
       "      <td>-121.916700</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Pueblo</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>38.175251</td>\n",
       "      <td>-104.519575</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>US-CT</td>\n",
       "      <td>41.671800</td>\n",
       "      <td>-72.949500</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Norwalk</td>\n",
       "      <td>US-CT</td>\n",
       "      <td>41.116700</td>\n",
       "      <td>-73.400000</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Glen Ellyn</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>41.883300</td>\n",
       "      <td>-88.066700</td>\n",
       "      <td>1901</td>\n",
       "      <td>12/25/00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    circle_name country_state        lat         lon  count_year  \\\n",
       "0           2  Pacific Grove         US-CA  36.616700 -121.916700        1901   \n",
       "1           3         Pueblo         US-CO  38.175251 -104.519575        1901   \n",
       "2           4        Bristol         US-CT  41.671800  -72.949500        1901   \n",
       "3           5        Norwalk         US-CT  41.116700  -73.400000        1901   \n",
       "4           6     Glen Ellyn         US-IL  41.883300  -88.066700        1901   \n",
       "\n",
       "  count_date  n_field_counters  n_feeder_counters  min_field_parties  ...  \\\n",
       "0   12/25/00               1.0                NaN                NaN  ...   \n",
       "1   12/25/00               1.0                NaN                NaN  ...   \n",
       "2   12/25/00               2.0                NaN                NaN  ...   \n",
       "3   12/25/00               1.0                NaN                NaN  ...   \n",
       "4   12/25/00               1.0                NaN                NaN  ...   \n",
       "\n",
       "   max_snow_metric  max_snow_imperial  min_temp_imperial  max_temp_imperial  \\\n",
       "0              NaN                NaN                NaN                NaN   \n",
       "1              NaN                NaN                NaN                NaN   \n",
       "2              NaN                NaN                NaN                NaN   \n",
       "3              NaN                NaN                NaN                NaN   \n",
       "4              NaN                NaN                NaN                NaN   \n",
       "\n",
       "   min_temp_metric  max_temp_metric min_wind_metric  max_wind_metric  \\\n",
       "0              NaN              NaN             NaN              NaN   \n",
       "1              NaN              NaN             NaN              NaN   \n",
       "2              NaN              NaN             NaN              NaN   \n",
       "3              NaN              NaN             NaN              NaN   \n",
       "4              NaN              NaN             NaN              NaN   \n",
       "\n",
       "   min_wind_imperial  max_wind_imperial  \n",
       "0                NaN                NaN  \n",
       "1                NaN                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push this data up to bigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Data name \n",
    "table_id = 'rec_initial_data_cleaning'\n",
    "\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "table_full = project + \".\"+ source_dataset_id + \".\" + \"rec_initial_data_cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted table 'birdproject-2020.audubon_cdc.rec_initial_data_cleaning'.\n"
     ]
    }
   ],
   "source": [
    "# Delete the exisiting table if it exisits so we can replace it with new data\n",
    "client.delete_table(table_full, not_found_ok=True)  # Make an API request.\n",
    "print(\"Deleted table '{}'.\".format(table_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 89568 rows into audubon_cdc:rec_initial_data_cleaning.\n"
     ]
    }
   ],
   "source": [
    "# Push our file up to BigQuery\n",
    "filename = PATH_TO_CLEAN_CBC_DATA\n",
    "\n",
    "# Build the Job Config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, source_dataset_id, table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Query and Submit it \n",
    "This is the query that interlaces the CDC bird count data, matches it with NOAA stations in close proximity with this station and then extracts the NOAA station weather measurements pertinenet to the dates. After the data is extracted the rows that have a NULL value of \"temp_min\" are pruned AND only USA weather measurements included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH circles_hash as (SELECT x.*, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 4) as geohash_circle, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 7) as circle_id\n",
    "\n",
    "FROM `{project}.audubon_cdc.rec_initial_data_cleaning` x),\n",
    "\n",
    "stations_hash as (SELECT y.*, ST_GEOHASH(ST_GEOGPOINT(y.longitude,y.latitude),4) as geohash_station FROM `bigquery-public-data`.ghcn_d.ghcnd_stations y),\n",
    "\n",
    "circle_with_matched_stations as (SELECT * FROM circles_hash x INNER JOIN stations_hash y ON x.geohash_circle = y.geohash_station)\n",
    "\n",
    "SELECT x.*, y.temp_min_value,y.temp_max_value,y.precipitation_value,y.temp_avg,y.snow,y.snwd\n",
    "\n",
    "FROM circle_with_matched_stations x\n",
    "LEFT JOIN `{project}.audubon_cdc.flatten_noaa_from_1900_to_present` y ON x.id = y.id AND x.count_date = y.date\n",
    "\n",
    "ORDER BY circle_id DESC,count_date ASC \"\"\"\n",
    "\n",
    "# Queries BigQuery public data set and creates a new dataframe object\n",
    "df_circles_to_stations_weather_data = client.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles_to_stations_weather_data = df_circles_to_stations_weather_data.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles_to_stations_weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving stations in csv COMPRESSED IN GZIP!!!\n",
    "df_circles_to_stations_weather_data.to_csv(r'1.1-circles_to_many_stations_usa_weather_data_' + str(time_now) +  '.csv', compression = \"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 records\n",
    "Showing the top 5 records of the data extracted to the query above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles_to_stations_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on dataset\n",
    "How many records are empty for the various temperature measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "record_count = len(df_circles_to_stations_weather_data.index)\n",
    "print('How many rows in dataset with missing vals: ', record_count)\n",
    "\n",
    "temp_min_nas = df_circles_to_stations_weather_data.temp_min_value.isna().sum()\n",
    "print(\"Missing min temperature: \" + str(temp_min_nas))\n",
    "\n",
    "temp_max_nas = df_circles_to_stations_weather_data.temp_max_value.isna().sum()\n",
    "print(\"Missing max temperature: \" + str(temp_max_nas))\n",
    "\n",
    "temp_avg_nas = df_circles_to_stations_weather_data.temp_avg.isna().sum()\n",
    "print(\"Missing avg temperature: \" + str(temp_avg_nas))\n",
    "\n",
    "snow = df_circles_to_stations_weather_data.snow.isna().sum()\n",
    "print(\"Missing snow temperature: \" + str(snow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty min/max temperature\n",
    "Create new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=df_circles_to_stations_weather_data.temp_min_value\n",
    "paired_data=df_circles_to_stations_weather_data[ref.notna()]\n",
    "paired_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of records in this data set is: \", len(paired_data.circle_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Data in the USA\n",
    "Create new data frame for stations only for stations located in the USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_usa = paired_data[paired_data.id.str.slice(stop=2)==\"US\"]\n",
    "print(\"The number of rows station usa weather data: \", len(paired_data_usa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving stations in csv COMPRESSED IN GZIP!!!\n",
    "paired_data_usa.to_csv(r'1.1-circles_to_many_stations_usa_weather_data_' + str(time_now) +  '.csv', compression = \"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

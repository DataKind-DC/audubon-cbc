{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Viz\n",
    "### Purpose\n",
    "The purpose of this notebook is to create some data visualizations to be used in the project sponser update.\n",
    "\n",
    "### Author: \n",
    "Ian Davis\n",
    "### Date: \n",
    "2020-09-05\n",
    "### Update Date: \n",
    "2020-09-05\n",
    "\n",
    "### Inputs \n",
    "1.3-rec-connecting-fips-ecosystem-data.csv - Comma separate file of the Christmas Bird Count and matches to 1 or more NOAA weather stations.\n",
    "- Data Dictonary can be found here: http://www.audubon.org/sites/default/files/documents/cbc_report_field_definitions_2013.pdf\n",
    "\n",
    "### Output Files\n",
    "Supporting data files:\n",
    "- 1.3.1-ijd-circles_and_fips.csv\n",
    "- 2.1-ijd-df_ts_circle_tmax.csv\n",
    "- 2.1-ijd-df_ts_noaa_tmax.csv\n",
    "\n",
    "Plot html's:\n",
    "- choropleth_ff_2010.html\n",
    "- choropleth_json_2010.html\n",
    "- circles.html\n",
    "- distance.html\n",
    "- elevation.html\n",
    "- matches.html\n",
    "- ts-map-anim_tmax.html\n",
    "- ts-map_tmax.html\n",
    "- ts_tmax.html\n",
    "\n",
    "## Steps or Proceedures in the notebook \n",
    "- Set runtime options\n",
    "- Import data\n",
    "- Plots\n",
    "    - Histogram of station distances\n",
    "\n",
    "## References\n",
    "- Figure Factory: # https://stackoverflow.com/questions/54734667/error-installing-geopandas-a-gdal-api-version-must-be-specified-in-anaconda\n",
    "- FIPS query: https://gis.stackexchange.com/questions/294641/python-code-for-transforming-lat-long-into-fips-codes\n",
    "- FIPS query: https://geo.fcc.gov/api/census/#!/block/get_block_find\n",
    "- Geojson: https://geoffboeing.com/2015/10/exporting-python-data-geojson/\n",
    "- Installing geopandas: https://stackoverflow.com/questions/54734667/error-installing-geopandas-a-gdal-api-version-must-be-specified-in-anaconda\n",
    "- Colorscale: https://plotly.com/python/county-choropleth/\n",
    "- Colors: http://www.impactlab.org/map/#usmeas=absolute&usyear=1981-2010&gmeas=absolute&gyear=1986-2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See data dictionary: \n",
    "\n",
    "http://www.audubon.org/sites/default/files/documents/cbc_report_field_definitions_2013.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# for plotting\n",
    "import plotly.express as px\n",
    "import plotly.offline as ply\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib\n",
    "\n",
    "# for GIS\n",
    "import requests\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "# add scripts folder to path\n",
    "sys.path.insert(1, '../scripts')\n",
    "\n",
    "# user import\n",
    "from calcs import main_calcs\n",
    "from calcs import haversine_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "PATH_TO_PAIRED_DATA = '../data/Cloud_data/1.3-rec-connecting-fips-ecosystem-data.txt'\n",
    "PATH_TO_FIPS = \"../data/Cloud_data/1.3.1-ijd-circles_and_fips.csv\"\n",
    "PATH_TO_TS_CIRCLE = \"../data/Cloud_data/2.1-ijd-df_ts_circle_tmax.csv\"\n",
    "PATH_TO_TS_NOAA = \"../data/Cloud_data/2.1-ijd-df_ts_noaa_tmax.csv\"\n",
    "\n",
    "# User Options\n",
    "offline_fips = True    # Get FIPS codes from offline .csv file\n",
    "offline_ts = True      # Read in time-series dataframes from .csv files\n",
    "popen = True           # Auto-open plot HTML files when generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query and get FIPS county codes.\n",
    "def get_fips(lat, lon):\n",
    "    # Encode parameters\n",
    "    params = urllib.parse.urlencode({'latitude': lat, 'longitude': lon, 'format': 'json'})\n",
    "    # Contruct request URL\n",
    "    url = 'https://geo.fcc.gov/api/census/block/find?' + params\n",
    "\n",
    "    # Get response from API\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse json in response\n",
    "    data = response.json()\n",
    "\n",
    "    fips = data['County']['FIPS']\n",
    "\n",
    "    print(lat, lon, fips)\n",
    "\n",
    "    try:\n",
    "        return str(fips)\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to geojson (UN-USED BELOW)\n",
    "def df_to_geojson(df, properties, lat='latitude', lon='longitude'):\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    for _, row in df.iterrows():\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "        feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        geojson['features'].append(feature)\n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of columns to read in\n",
    "# IJD: I was running into memory issues loading the whole dataset\n",
    "# Only read in certain columns\n",
    "fields = ['circle_name',\n",
    "          'circle_id',\n",
    "          'id',\n",
    "          'ui',\n",
    "          'lat',              # circle\n",
    "          'lon',              # circle\n",
    "          'county_fips',      # circle\n",
    "          'country_state',\n",
    "          'count_year',\n",
    "          'count_date',\n",
    "          'latitude',         # noaa\n",
    "          'longitude',        # noaa\n",
    "          'circle_elev',      # circle\n",
    "          'elevation',        # noaa\n",
    "          'min_snow',         # circle\n",
    "          'max_snow',         # circle\n",
    "          'am_rain',          # circle\n",
    "          'pm_rain',          # circle\n",
    "          'max_temp',         # circle\n",
    "          'min_temp',         # circle\n",
    "          'temp_max_value',   # noaa\n",
    "          'temp_min_value'    # noaa\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning:\n",
      "\n",
      "Columns (62) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "df_paired = pd.read_csv(PATH_TO_PAIRED_DATA,\n",
    "                        compression='gzip',\n",
    "                        sep='\\t',\n",
    "                        skipinitialspace=True,\n",
    "                        usecols=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Screening & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied in some calculations from calcs.py\n",
    "for chunk in np.array_split(df_paired, 4):\n",
    "    df_paired.loc[chunk.index, 'distance'] = df_paired.loc[chunk.index, ['lat', 'lon', 'latitude', 'longitude']].apply(haversine_formula, axis=1)\n",
    "\n",
    "    # calculate elevation difference between circles and stations\n",
    "    df_paired.loc[chunk.index, 'elev_diff'] = df_paired.loc[chunk.index, 'circle_elev'] - df_paired.loc[chunk.index, 'elevation']\n",
    "    df_paired.loc[chunk.index, 'elev_diff'] = df_paired.loc[chunk.index, 'elev_diff'].abs()\n",
    "    \n",
    "    # Convert NOAA temperatures from a tenth of a degree to degrees\n",
    "    df_paired.loc[:, 'noaa_tmax_value'] = df_paired.loc[:, 'temp_max_value'] / 10.0 * 1.8 + 32.0\n",
    "    df_paired.loc[:, 'noaa_tmin_value'] = df_paired.loc[:, 'temp_min_value'] / 10.0 * 1.8 + 32.0\n",
    "\n",
    "    # Remove temperature errors\n",
    "    df_paired.loc[df_paired['max_temp'] > 150.0, 'max_temp'] = np.nan\n",
    "    df_paired.loc[df_paired['noaa_tmax_value'] > 150.0, 'noaa_tmax_value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique Lat Lon combos in the dataset is: \n",
      "(756378, 5)\n",
      "(3848, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create a Temportary String to Merge on\n",
    "df_paired['temp_key_str'] = round(df_paired['lat'],3).astype(str) + round(df_paired['lon'],3).astype(str)\n",
    "print(\"The number of unique Lat Lon combos in the dataset is: \")\n",
    "df_paired['temp_key_str'].nunique()\n",
    "\n",
    "df_circle = df_paired[[\"lat\", \"lon\", \"temp_key_str\", \"circle_name\", \"county_fips\"]]\n",
    "print(df_circle.shape)\n",
    "df_circle = df_circle.drop_duplicates(\"temp_key_str\")\n",
    "print(df_circle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US-HI', 'US-FL', 'US-TX', 'US-LA', 'US-AL', 'US-MS', 'US-GA',\n",
       "       'US-AZ', 'US-NM', 'US-SC', 'US-CA', 'US-AR', 'US-OK', 'US-NC',\n",
       "       'US-TN', 'US-NV', 'US-MO', 'US-VA', 'US-KY', 'US-UT', 'US-KS',\n",
       "       'US-IL', 'US-CO', 'US-WV', 'US-IN', 'US-MD', 'US-DE', 'US-OH',\n",
       "       'US-DC', 'US-NJ', 'US-PA', 'US-NE', 'US-NY', 'US-IA', 'US-CT',\n",
       "       'US-WY', 'US-RI', 'US-MA', 'US-MI', 'US-ID', 'US-OR', 'US-WI',\n",
       "       'US-SD', 'US-NH', 'US-VT', 'US-ME', 'US-MN', 'US-MT', 'US-WA',\n",
       "       'US-ND', 'US-AK'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure all state strings are uppercase\n",
    "df_paired.loc[df_paired['country_state'] == 'us-fl', 'country_state'] = 'US-FL'\n",
    "df_paired.loc[df_paired['country_state'] == 'us-ma', 'country_state'] = 'US-MA'\n",
    "df_paired.loc[df_paired['country_state'] == 'us-wi', 'country_state'] = 'US-WI'\n",
    "df_paired.loc[df_paired['country_state'] == 'us-mn', 'country_state'] = 'US-MN'\n",
    "\n",
    "df_paired['country_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_paired['country_state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create states only column\n",
    "df_paired.loc[:, 'state'] = df_paired.loc[:, 'country_state'].apply(lambda x: x.lstrip('US'))\n",
    "df_paired.loc[:, 'state'] = df_paired.loc[:, 'state'].apply(lambda x: x.lstrip('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HI' 'FL' 'TX' 'LA' 'AL' 'MS' 'GA' 'AZ' 'NM' 'SC' 'CA' 'AR' 'OK' 'NC'\n",
      " 'TN' 'NV' 'MO' 'VA' 'KY' 'UT' 'KS' 'IL' 'CO' 'WV' 'IN' 'MD' 'DE' 'OH'\n",
      " 'DC' 'NJ' 'PA' 'NE' 'NY' 'IA' 'CT' 'WY' 'RI' 'MA' 'MI' 'ID' 'OR' 'WI'\n",
      " 'SD' 'NH' 'VT' 'ME' 'MN' 'MT' 'WA' 'ND' 'AK']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(df_paired.loc[:, 'state'].unique())\n",
    "print(len(df_paired.loc[:, 'state'].unique())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get County FIPS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get County FIPS codes (already ran this and saved the output to a .csv file)\n",
    "\n",
    "if not offline_fips:\n",
    "    df_circle.loc[:, 'county_fips'] = df_circle.loc[:, ['lat', 'lon']].apply(lambda x: get_fips(x['lat'], x['lon']), axis=1)\n",
    "    # Save to CSV\n",
    "    df_circle.to_csv(PATH_TO_FIPS, index=False)\n",
    "else:\n",
    "    df_circle = pd.read_csv(PATH_TO_FIPS,\n",
    "                            dtype={'lat': float,\n",
    "                                   'lon': float,\n",
    "                                   'temp_key_str': str,\n",
    "                                   'circle_name': str,\n",
    "                                   'county_fips': str})\n",
    "\n",
    "# Drop existing FIPS column\n",
    "df_paired.drop('county_fips', axis=1, inplace=True)\n",
    "# Merge with original dataset\n",
    "df_paired = pd.merge(df_paired,\n",
    "                     df_circle[['temp_key_str', 'county_fips']],\n",
    "                     on=['temp_key_str'],\n",
    "                     how='left',\n",
    "                     copy=False\n",
    "                     )\n",
    "\n",
    "# Convert FIPS errors to nan's\n",
    "df_paired.loc[df_paired['county_fips'] == 'None'] = np.nan\n",
    "df_paired.loc[df_paired['county_fips'] == ''] = np.nan\n",
    "\n",
    "# Sanity check (should be less that 2000 NaN's for county_fips\n",
    "print('The number of county_fips Nan\\'s is:')\n",
    "print(df_paired['county_fips'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Circle Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map plot of all unique circles\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "        lon = df_circle['lon'],\n",
    "        lat = df_circle['lat'],\n",
    "        text = df_circle['circle_name'],\n",
    "        mode = 'markers',\n",
    "        marker=dict(opacity=0.4,\n",
    "                    color=\"black\")\n",
    "        ))\n",
    "fig.update_layout(\n",
    "        title = 'Unique Circle Locations',\n",
    "        geo_scope='usa',\n",
    "    )\n",
    "ply.plot(fig, filename='../plots/circles.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circle to NOAA Station Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of distances\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df_paired['distance'],\n",
    "                           nbinsx=50))\n",
    "fig.update_layout(title=\"Histogram of Distances Between Circles and Stations\",\n",
    "                  template=\"simple_white\")\n",
    "fig.update_xaxes(title_text='Distance [m]')\n",
    "fig.update_yaxes(title_text='Counts')\n",
    "ply.plot(fig, filename='../plots/distance.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Matched Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of station matches\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df_paired['ui'].value_counts(),\n",
    "                           xbins=dict(start=0,\n",
    "                                      end=50,\n",
    "                                      size=1)))\n",
    "fig.update_layout(title=\"Histogram of NOAA Station Matches\",\n",
    "                  template=\"simple_white\")\n",
    "fig.update_xaxes(title_text='Number of Stations Matched')\n",
    "fig.update_yaxes(title_text='Counts')\n",
    "ply.plot(fig, filename='../plots/matches.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of elevation difference\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df_paired['elev_diff'],\n",
    "                           xbins=dict(start=0,\n",
    "                                      end=500,\n",
    "                                      size=10)))\n",
    "fig.update_layout(title=\"Histogram of Elevation Difference Between Circles and Stations\",\n",
    "                  template=\"simple_white\")\n",
    "fig.update_xaxes(title_text='Elevation Change [m]')\n",
    "fig.update_yaxes(title_text='Counts')\n",
    "ply.plot(fig, filename='../plots/elevation.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Factory Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for 2010 data\n",
    "df_2010 = df_paired.loc[df_paired['count_year'] == 2010, ['lat', 'lon', 'country_state', 'max_temp', 'min_temp', 'county_fips']]\n",
    "df_2010 = df_2010.dropna(axis=0, subset=['max_temp', 'county_fips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "fips = df_2010['county_fips'].tolist()\n",
    "values = df_2010['max_temp'].tolist()\n",
    "\n",
    "colorscale = [\n",
    "    '#00ACC1',\n",
    "    '#26C6DA',\n",
    "    '#B2EBF2',\n",
    "    \"#FFF9C4\",\n",
    "    '#FFEE58',\n",
    "    '#FBC02D',\n",
    "    '#FF7043',\n",
    "    '#E64A19',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_choropleth(\n",
    "    fips=fips, values=values, scope=['usa'],\n",
    "    show_state_data=True,\n",
    "    show_hover=True,\n",
    "    asp = 2.9,\n",
    "    title_text = 'Maximum Circle Temps - 2010',\n",
    "    legend_title = 'Temperature [F]',\n",
    "    binning_endpoints=[-100.0, 0.0, 10.0, 20.0, 30.0, 40.0, 50.0],\n",
    "    colorscale=colorscale,\n",
    ")\n",
    "fig.layout.template = None\n",
    "\n",
    "ply.plot(fig, filename='../plots/choropleth_ff.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choropleth Map from GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download U.S. counties in JSON format\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "    \n",
    "# Write to txt file\n",
    "#with open('../data/Cloud_Data/counties.json', 'w', encoding='utf-8') as f:\n",
    "#    json.dump(counties, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth_mapbox(df_2010, geojson=counties, locations='county_fips', color='max_temp',\n",
    "                           color_continuous_scale=\"Reds\",\n",
    "                           range_color=(0, 100),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'max_temp':'Maximum Temperature'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "ply.plot(fig, filename='../plots/choropleth_json2.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paired['max_temp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at California counties\n",
    "df_2010.loc[df_2010['country_state'] == 'US-CA', ['lat', 'lon', 'county_fips', 'max_temp']].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the counties JSON variable, CA is state \"06\".\n",
    "There are 58 counties in CA (as of 2010 census), and it looks like all are included in the JSON variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CA only dataframe\n",
    "df_2010_CA = df_2010.loc[df_2010['country_state'] == 'US-CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that CA temperature data exists\n",
    "df_2010_CA['max_temp'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series Chart Averaged by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
       "       'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
       "       'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
       "       'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
       "       'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique states\n",
    "states = df_paired['state'].unique()\n",
    "states = np.sort(states)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911,\n",
       "       1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922,\n",
       "       1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933,\n",
       "       1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944,\n",
       "       1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955,\n",
       "       1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966,\n",
       "       1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977,\n",
       "       1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988,\n",
       "       1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "       2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n",
       "       2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique years\n",
    "years = df_paired['count_year'].unique()\n",
    "years = np.sort(years)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911,\n",
       "       1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922,\n",
       "       1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933,\n",
       "       1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944,\n",
       "       1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955,\n",
       "       1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966,\n",
       "       1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977,\n",
       "       1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988,\n",
       "       1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "       2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n",
       "       2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.329990884229716"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paired.loc[(df_paired['count_year'] == 2010) & (df_paired['state'] == 'CA'), 'max_temp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time-series dataframe for the Circles Max Temp\n",
    "if not offline_ts:\n",
    "\n",
    "    # Create a blank time-series dataframe\n",
    "    df_ts_circle_tmax = pd.DataFrame(index=years,\n",
    "                                     columns=states)\n",
    "\n",
    "    # Loop through years and states to get averages\n",
    "    for yr in years:\n",
    "        for st in states:\n",
    "            df_ts_circle_tmax.loc[yr, st] = df_paired.loc[(df_paired['count_year'] == yr) &\n",
    "                                                          (df_paired['state'] == st),\n",
    "                                                          'max_temp'].mean()\n",
    "        \n",
    "    df_ts_circle_tmax.to_csv(PATH_TO_TS_CIRCLE)\n",
    "\n",
    "else:\n",
    "    df_ts_circle_tmax = pd.read_csv(PATH_TO_TS_CIRCLE,\n",
    "                                    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time-series dataframe for the NOAA Max Temp\n",
    "\n",
    "if not offline_ts:\n",
    "    # Create a blank time-series dataframe\n",
    "    df_ts_noaa_tmax = pd.DataFrame(index=years,\n",
    "                                   columns=states)\n",
    "\n",
    "    # Loop through years and states to get averages\n",
    "    for yr in years:\n",
    "        for st in states:\n",
    "            df_ts_noaa_tmax.loc[yr, st] = df_paired.loc[(df_paired['count_year'] == yr) &\n",
    "                                                        (df_paired['state'] == st),\n",
    "                                                        'noaa_tmax_value'].mean()\n",
    "        \n",
    "    df_ts_noaa_tmax.to_csv(PATH_TO_TS_NOAA)\n",
    "\n",
    "else:\n",
    "    df_ts_noaa_tmax = pd.read_csv(PATH_TO_TS_NOAA,\n",
    "                                  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AK</th>\n",
       "      <th>AL</th>\n",
       "      <th>AR</th>\n",
       "      <th>AZ</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>DC</th>\n",
       "      <th>DE</th>\n",
       "      <th>FL</th>\n",
       "      <th>...</th>\n",
       "      <th>SD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>UT</th>\n",
       "      <th>VA</th>\n",
       "      <th>VT</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "      <th>WV</th>\n",
       "      <th>WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>23.916667</td>\n",
       "      <td>54.683544</td>\n",
       "      <td>50.987805</td>\n",
       "      <td>61.738903</td>\n",
       "      <td>65.168728</td>\n",
       "      <td>43.372162</td>\n",
       "      <td>37.065476</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.617647</td>\n",
       "      <td>74.549296</td>\n",
       "      <td>...</td>\n",
       "      <td>28.987578</td>\n",
       "      <td>50.507212</td>\n",
       "      <td>58.792683</td>\n",
       "      <td>32.670466</td>\n",
       "      <td>46.730479</td>\n",
       "      <td>25.376923</td>\n",
       "      <td>45.832609</td>\n",
       "      <td>23.694274</td>\n",
       "      <td>50.625000</td>\n",
       "      <td>33.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>30.551562</td>\n",
       "      <td>59.431373</td>\n",
       "      <td>50.151445</td>\n",
       "      <td>51.239075</td>\n",
       "      <td>59.652495</td>\n",
       "      <td>38.985250</td>\n",
       "      <td>39.596273</td>\n",
       "      <td>39.0</td>\n",
       "      <td>52.415094</td>\n",
       "      <td>74.643347</td>\n",
       "      <td>...</td>\n",
       "      <td>31.924658</td>\n",
       "      <td>49.891247</td>\n",
       "      <td>55.592638</td>\n",
       "      <td>36.940367</td>\n",
       "      <td>51.240933</td>\n",
       "      <td>33.297101</td>\n",
       "      <td>45.288201</td>\n",
       "      <td>33.839623</td>\n",
       "      <td>44.159292</td>\n",
       "      <td>28.990950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>32.917241</td>\n",
       "      <td>61.068627</td>\n",
       "      <td>52.800000</td>\n",
       "      <td>48.323980</td>\n",
       "      <td>55.693576</td>\n",
       "      <td>42.583204</td>\n",
       "      <td>43.487805</td>\n",
       "      <td>45.0</td>\n",
       "      <td>47.584906</td>\n",
       "      <td>72.773678</td>\n",
       "      <td>...</td>\n",
       "      <td>30.360248</td>\n",
       "      <td>53.888078</td>\n",
       "      <td>59.562101</td>\n",
       "      <td>39.067273</td>\n",
       "      <td>51.652393</td>\n",
       "      <td>34.628099</td>\n",
       "      <td>40.321298</td>\n",
       "      <td>30.254095</td>\n",
       "      <td>47.838095</td>\n",
       "      <td>35.515385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>27.474820</td>\n",
       "      <td>65.803738</td>\n",
       "      <td>47.622222</td>\n",
       "      <td>66.123529</td>\n",
       "      <td>54.854844</td>\n",
       "      <td>30.078493</td>\n",
       "      <td>45.538117</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.268293</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.772727</td>\n",
       "      <td>51.446753</td>\n",
       "      <td>66.073937</td>\n",
       "      <td>30.214592</td>\n",
       "      <td>54.161290</td>\n",
       "      <td>31.545455</td>\n",
       "      <td>34.906883</td>\n",
       "      <td>22.354776</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>31.204633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>31.463576</td>\n",
       "      <td>55.129630</td>\n",
       "      <td>47.114130</td>\n",
       "      <td>66.586957</td>\n",
       "      <td>63.814057</td>\n",
       "      <td>44.619803</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>35.566038</td>\n",
       "      <td>71.262662</td>\n",
       "      <td>...</td>\n",
       "      <td>31.832258</td>\n",
       "      <td>41.975831</td>\n",
       "      <td>54.557354</td>\n",
       "      <td>41.488995</td>\n",
       "      <td>40.038363</td>\n",
       "      <td>17.607333</td>\n",
       "      <td>43.062619</td>\n",
       "      <td>25.487572</td>\n",
       "      <td>37.228333</td>\n",
       "      <td>37.817427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AK         AL         AR         AZ         CA         CO  \\\n",
       "2014  23.916667  54.683544  50.987805  61.738903  65.168728  43.372162   \n",
       "2015  30.551562  59.431373  50.151445  51.239075  59.652495  38.985250   \n",
       "2016  32.917241  61.068627  52.800000  48.323980  55.693576  42.583204   \n",
       "2017  27.474820  65.803738  47.622222  66.123529  54.854844  30.078493   \n",
       "2018  31.463576  55.129630  47.114130  66.586957  63.814057  44.619803   \n",
       "\n",
       "             CT    DC         DE         FL  ...         SD         TN  \\\n",
       "2014  37.065476  42.0  44.617647  74.549296  ...  28.987578  50.507212   \n",
       "2015  39.596273  39.0  52.415094  74.643347  ...  31.924658  49.891247   \n",
       "2016  43.487805  45.0  47.584906  72.773678  ...  30.360248  53.888078   \n",
       "2017  45.538117  50.0  46.268293  77.700000  ...  32.772727  51.446753   \n",
       "2018  31.600000  48.0  35.566038  71.262662  ...  31.832258  41.975831   \n",
       "\n",
       "             TX         UT         VA         VT         WA         WI  \\\n",
       "2014  58.792683  32.670466  46.730479  25.376923  45.832609  23.694274   \n",
       "2015  55.592638  36.940367  51.240933  33.297101  45.288201  33.839623   \n",
       "2016  59.562101  39.067273  51.652393  34.628099  40.321298  30.254095   \n",
       "2017  66.073937  30.214592  54.161290  31.545455  34.906883  22.354776   \n",
       "2018  54.557354  41.488995  40.038363  17.607333  43.062619  25.487572   \n",
       "\n",
       "             WV         WY  \n",
       "2014  50.625000  33.403846  \n",
       "2015  44.159292  28.990950  \n",
       "2016  47.838095  35.515385  \n",
       "2017  52.400000  31.204633  \n",
       "2018  37.228333  37.817427  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure daaframe contains data\n",
    "df_ts_circle_tmax.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AK</th>\n",
       "      <th>AL</th>\n",
       "      <th>AR</th>\n",
       "      <th>AZ</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>DC</th>\n",
       "      <th>DE</th>\n",
       "      <th>FL</th>\n",
       "      <th>...</th>\n",
       "      <th>SD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>UT</th>\n",
       "      <th>VA</th>\n",
       "      <th>VT</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "      <th>WV</th>\n",
       "      <th>WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>22.042727</td>\n",
       "      <td>62.600</td>\n",
       "      <td>54.876364</td>\n",
       "      <td>56.488780</td>\n",
       "      <td>63.609565</td>\n",
       "      <td>40.137500</td>\n",
       "      <td>34.823750</td>\n",
       "      <td>41.36</td>\n",
       "      <td>54.50</td>\n",
       "      <td>75.178276</td>\n",
       "      <td>...</td>\n",
       "      <td>35.162857</td>\n",
       "      <td>46.996000</td>\n",
       "      <td>59.835313</td>\n",
       "      <td>34.602286</td>\n",
       "      <td>46.730698</td>\n",
       "      <td>20.457500</td>\n",
       "      <td>43.320851</td>\n",
       "      <td>23.516226</td>\n",
       "      <td>51.911429</td>\n",
       "      <td>35.126667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>32.395122</td>\n",
       "      <td>58.145</td>\n",
       "      <td>49.827826</td>\n",
       "      <td>51.460000</td>\n",
       "      <td>55.416744</td>\n",
       "      <td>35.957429</td>\n",
       "      <td>36.341176</td>\n",
       "      <td>37.70</td>\n",
       "      <td>55.58</td>\n",
       "      <td>74.607742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.176000</td>\n",
       "      <td>50.396923</td>\n",
       "      <td>57.586777</td>\n",
       "      <td>38.192000</td>\n",
       "      <td>50.755122</td>\n",
       "      <td>32.652500</td>\n",
       "      <td>43.167660</td>\n",
       "      <td>34.355728</td>\n",
       "      <td>43.134286</td>\n",
       "      <td>31.833846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>32.715610</td>\n",
       "      <td>59.700</td>\n",
       "      <td>56.604615</td>\n",
       "      <td>52.054348</td>\n",
       "      <td>52.470909</td>\n",
       "      <td>37.736857</td>\n",
       "      <td>42.991250</td>\n",
       "      <td>44.96</td>\n",
       "      <td>38.30</td>\n",
       "      <td>77.110323</td>\n",
       "      <td>...</td>\n",
       "      <td>31.742857</td>\n",
       "      <td>51.283684</td>\n",
       "      <td>60.327500</td>\n",
       "      <td>36.592195</td>\n",
       "      <td>51.378636</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>38.271364</td>\n",
       "      <td>33.011600</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>31.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>25.403529</td>\n",
       "      <td>68.135</td>\n",
       "      <td>50.994286</td>\n",
       "      <td>56.541364</td>\n",
       "      <td>52.091236</td>\n",
       "      <td>33.526197</td>\n",
       "      <td>46.892632</td>\n",
       "      <td>38.03</td>\n",
       "      <td>32.54</td>\n",
       "      <td>79.991000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.004706</td>\n",
       "      <td>50.065455</td>\n",
       "      <td>68.143390</td>\n",
       "      <td>37.089091</td>\n",
       "      <td>53.687568</td>\n",
       "      <td>28.053846</td>\n",
       "      <td>32.873000</td>\n",
       "      <td>19.532955</td>\n",
       "      <td>50.104211</td>\n",
       "      <td>30.315714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>32.714194</td>\n",
       "      <td>54.020</td>\n",
       "      <td>49.004706</td>\n",
       "      <td>61.064375</td>\n",
       "      <td>60.357452</td>\n",
       "      <td>40.899672</td>\n",
       "      <td>31.430000</td>\n",
       "      <td>38.48</td>\n",
       "      <td>39.38</td>\n",
       "      <td>72.775094</td>\n",
       "      <td>...</td>\n",
       "      <td>31.232000</td>\n",
       "      <td>43.940000</td>\n",
       "      <td>57.768868</td>\n",
       "      <td>41.016364</td>\n",
       "      <td>40.825000</td>\n",
       "      <td>16.520000</td>\n",
       "      <td>41.484138</td>\n",
       "      <td>25.853409</td>\n",
       "      <td>33.597500</td>\n",
       "      <td>31.258400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AK      AL         AR         AZ         CA         CO  \\\n",
       "2014  22.042727  62.600  54.876364  56.488780  63.609565  40.137500   \n",
       "2015  32.395122  58.145  49.827826  51.460000  55.416744  35.957429   \n",
       "2016  32.715610  59.700  56.604615  52.054348  52.470909  37.736857   \n",
       "2017  25.403529  68.135  50.994286  56.541364  52.091236  33.526197   \n",
       "2018  32.714194  54.020  49.004706  61.064375  60.357452  40.899672   \n",
       "\n",
       "             CT     DC     DE         FL  ...         SD         TN  \\\n",
       "2014  34.823750  41.36  54.50  75.178276  ...  35.162857  46.996000   \n",
       "2015  36.341176  37.70  55.58  74.607742  ...  27.176000  50.396923   \n",
       "2016  42.991250  44.96  38.30  77.110323  ...  31.742857  51.283684   \n",
       "2017  46.892632  38.03  32.54  79.991000  ...  31.004706  50.065455   \n",
       "2018  31.430000  38.48  39.38  72.775094  ...  31.232000  43.940000   \n",
       "\n",
       "             TX         UT         VA         VT         WA         WI  \\\n",
       "2014  59.835313  34.602286  46.730698  20.457500  43.320851  23.516226   \n",
       "2015  57.586777  38.192000  50.755122  32.652500  43.167660  34.355728   \n",
       "2016  60.327500  36.592195  51.378636  37.580000  38.271364  33.011600   \n",
       "2017  68.143390  37.089091  53.687568  28.053846  32.873000  19.532955   \n",
       "2018  57.768868  41.016364  40.825000  16.520000  41.484138  25.853409   \n",
       "\n",
       "             WV         WY  \n",
       "2014  51.911429  35.126667  \n",
       "2015  43.134286  31.833846  \n",
       "2016  42.600000  31.433333  \n",
       "2017  50.104211  30.315714  \n",
       "2018  33.597500  31.258400  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure dataframe contains data\n",
    "df_ts_noaa_tmax.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes and convert to long format\n",
    "df_ts_circle_tmax_long = pd.melt(df_ts_circle_tmax,\n",
    "                                 var_name='state',\n",
    "                                 value_name='circle_tmax',\n",
    "                                 ignore_index=False)\n",
    "\n",
    "df_ts_noaa_tmax_long = pd.melt(df_ts_noaa_tmax,\n",
    "                                 var_name='state',\n",
    "                                 value_name='circle_tmax',\n",
    "                                 ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
       "       'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
       "       'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
       "       'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
       "       'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_circle_tmax_long['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>circle_tmax</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6013</th>\n",
       "      <td>WY</td>\n",
       "      <td>33.403846</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>WY</td>\n",
       "      <td>28.990950</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>WY</td>\n",
       "      <td>35.515385</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>WY</td>\n",
       "      <td>31.204633</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>WY</td>\n",
       "      <td>37.817427</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  circle_tmax  year\n",
       "6013    WY    33.403846  2014\n",
       "6014    WY    28.990950  2015\n",
       "6015    WY    35.515385  2016\n",
       "6016    WY    31.204633  2017\n",
       "6017    WY    37.817427  2018"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the index to a normal column\n",
    "df_ts_circle_tmax_long['year'] = df_ts_circle_tmax_long.index\n",
    "df_ts_circle_tmax_long.reset_index(drop=True, inplace=True)\n",
    "df_ts_circle_tmax_long.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../plots/ts_tmax.html'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make line plot\n",
    "x_all = df_ts_circle_tmax.index\n",
    "y1 = df_ts_circle_tmax.loc[:, 'FL']\n",
    "name1 = 'FL-circle'\n",
    "y2 = df_ts_noaa_tmax.loc[:, 'FL']\n",
    "name2 = 'FL-noaa'\n",
    "y3 = df_ts_circle_tmax.loc[:, 'TX']\n",
    "name3 = 'TX-circle'\n",
    "y4 = df_ts_noaa_tmax.loc[:, 'TX']\n",
    "name4 = 'TX-noaa'\n",
    "y5 = df_ts_circle_tmax.loc[:, 'WA']\n",
    "name5 = 'WA-circle'\n",
    "y6 = df_ts_noaa_tmax.loc[:, 'WA']\n",
    "name6 = 'WA-noaa'\n",
    "y7 = df_ts_circle_tmax.loc[:, 'VT']\n",
    "name7 = 'VT-circle'\n",
    "y8 = df_ts_noaa_tmax.loc[:, 'VT']\n",
    "name8 = 'VT-noaa'\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y1,\n",
    "                         name=name1,\n",
    "                         line=dict(color='firebrick', dash='solid')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y2,\n",
    "                         name=name2,\n",
    "                         line=dict(color='firebrick', dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y3,\n",
    "                         name=name3,\n",
    "                         line=dict(color='royalblue', dash='solid')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y4,\n",
    "                         name=name4,\n",
    "                         line=dict(color='royalblue', dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y5,\n",
    "                         name=name5,\n",
    "                         line=dict(color='black', dash='solid')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y6,\n",
    "                         name=name6,\n",
    "                         line=dict(color='black', dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y7,\n",
    "                         name=name7,\n",
    "                         line=dict(color='lightgreen', dash='solid')))\n",
    "fig.add_trace(go.Scatter(x=x_all, y=y8,\n",
    "                         name=name8,\n",
    "                         line=dict(color='lightgreen', dash='dot')))\n",
    "fig.update_layout(title=\"Time-Series Comparison b/w Circles and NOAA Stations: Tmax\",\n",
    "                  template=\"simple_white\")\n",
    "fig.update_xaxes(title_text='Year')\n",
    "fig.update_yaxes(title_text='Max Temperature [F]',\n",
    "                 range=[0, 100])\n",
    "ply.plot(fig, filename='../plots/ts_tmax.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Choropleth Map with Time Scale Slider\n",
    "\n",
    "ref: https://amaral.northwestern.edu/blog/step-step-how-plot-map-slider-represent-time-evolu\n",
    "ref: https://support.sisense.com/hc/en-us/community/posts/360038301533-Plotly-Choropleth-With-Slider-Map-Charts-Over-Time-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../plots/ts-map_tmax.html'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colorscale\n",
    "scl = [[0.0, '#ffffff'],[0.2, '#ff9999'],[0.4, '#ff4d4d'], \\\n",
    "       [0.6, '#ff1a1a'],[0.8, '#cc0000'],[1.0, '#4d0000']] # reds\n",
    "\n",
    "### create empty list for data object:    \n",
    "data_slider = []\n",
    "\n",
    "#### I populate the data object\n",
    "# 'years' is a np.array from above\n",
    "for year in years:\n",
    "    # I select the year (and remove DC for now)\n",
    "    df_selected_year = df_ts_circle_tmax_long[(df_ts_circle_tmax_long['state']!= 'DC' ) &  \\\n",
    "                                              (df_ts_circle_tmax_long['year']== year )]\n",
    "\n",
    "    ### I create the text for mouse-hover for each state, for the current year    \n",
    "    df_selected_year['text'] = '[degF]'\n",
    "\n",
    "    ### create the dictionary with the data for the current year\n",
    "    data_one_year = dict(\n",
    "                        type='choropleth',\n",
    "                        locations = df_selected_year['state'],\n",
    "                        z=df_selected_year['circle_tmax'],\n",
    "                        locationmode='USA-states',\n",
    "                        colorscale = scl,\n",
    "                        text = df_selected_year['text'],\n",
    "                        zmin=0,\n",
    "                        zmax=75,\n",
    "                        colorbar= {'title':'Tempareature [degF]'}\n",
    "                        )\n",
    "\n",
    "    data_slider.append(data_one_year)  # I add the dictionary to the list of dictionaries for the slider\n",
    "    \n",
    "##  I create the steps for the slider\n",
    "steps = []\n",
    "\n",
    "for i in range(len(data_slider)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(data_slider)],\n",
    "                label='{}'.format(i + 1901)) # label to be displayed for each step (year)\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "\n",
    "##  I create the 'sliders' object from the 'steps' \n",
    "sliders = [dict(active=0, pad={\"t\": 1}, steps=steps)]\n",
    "\n",
    "# I set up the layout (including slider option)\n",
    "layout = dict(geo=dict(scope='usa',\n",
    "                       projection={'type': 'albers usa'}),\n",
    "                       sliders=sliders,\n",
    "              title='Circle Max Temperatures Averaged by State',\n",
    "              updatemenus=[dict(\n",
    "                               type=\"buttons\",\n",
    "                               buttons=[dict(label=\"Play\",\n",
    "                               method=\"animate\",\n",
    "                               args=[None])])])\n",
    "\n",
    "# I create the figure object:\n",
    "fig = dict(data=data_slider, layout=layout)\n",
    "\n",
    "# to plot in the notebook\n",
    "#ply.iplot(fig)\n",
    "\n",
    "# to plot in a separete browser window\n",
    "ply.plot(fig, filename='../plots/ts-map_tmax.html', auto_open=popen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated Choropleth Map\n",
    "\n",
    "ref:https://towardsdatascience.com/how-to-create-an-animated-choropleth-map-with-less-than-15-lines-of-code-2ff04921c60b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../plots/ts-map-anim_tmax.html'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = px.choropleth(df_ts_circle_tmax_long, \n",
    "              locations = 'state',\n",
    "              color=\"circle_tmax\", \n",
    "              animation_frame=\"year\",\n",
    "              color_continuous_scale=\"Reds\",\n",
    "              locationmode='USA-states',\n",
    "              scope=\"usa\",\n",
    "              range_color=(0, 75),\n",
    "              title='Circle Max Temperatures Averaged by State',\n",
    "              height=600,\n",
    "              labels={'circle_tmax': 'Temperature [degF]',\n",
    "                      'year': 'Year '}\n",
    "             )\n",
    "\n",
    "fig.update_layout(legend_title_text='Temperature [degF]')\n",
    "ply.plot(fig, filename='../plots/ts-map-anim_tmax.html', auto_open=popen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

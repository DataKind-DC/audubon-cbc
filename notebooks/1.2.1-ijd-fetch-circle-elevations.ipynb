{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Circle Elevations\n",
    "### Purpose\n",
    "In this notebook I query the USGS to get elevation data for all of the circles.\n",
    "This notebook addresses some one of the tasks in Github issue #35\n",
    "\n",
    "### Author: \n",
    "Ian Davis\n",
    "### Date: \n",
    "2020-03-31\n",
    "### Update Date: \n",
    "2020-07-09\n",
    "\n",
    "### Inputs \n",
    "1.1-circles_to_many_stations_usa_weather_data_20200424213015.txt - Tab separated file of the Christmas Bird Count and matches to 1 or more NOAA weather stations.\n",
    "- Data Dictonary can be found here: http://www.audubon.org/sites/default/files/documents/cbc_report_field_definitions_2013.pdf\n",
    "\n",
    "1.0-rec-initial-data-cleaning.txt - Tab seperated file of cleaned cbc data where each row is a circle count infomation for a given count year. \n",
    "\n",
    "1.2.1-ijd-fetch-circle-elevations-OFFLINE.csv - Previously generated elevation data. This file will be used when you want to get the elevation data from an offline source and aoivd 100,000+ queries.\n",
    "\n",
    "### Output Files\n",
    "1.2-ijd-fetch-circle-elevations_20200502155633.csv - Only 1 column is added to the dataset, 'circle_elev'. This column is the elevation in meters for a given latitude and longitude of the circle centroid.\n",
    "\n",
    "## Steps or Proceedures in the notebook \n",
    "- Set runtime options\n",
    "    - Set option to retrieve elevations from offline source, or through the USGS queries\n",
    "    - Set option to only test the USGS query (NOTE: running the query function for the whole dataset will take 24+ hours)\n",
    "- Create a function to make a remote request to the USGS API\n",
    "- Create a function to supply inputs to the remote request and return the elevation value\n",
    "- Main sequence\n",
    "    - Read in dataset\n",
    "    - Create a list of unique lat lon combinations \n",
    "    - Loop through the unique lat lons to get elevation data from usgs\n",
    "    - (Optional) Retrieve elevations from offline data source instead of queries\n",
    "    - Merge in the unique lat lon data with the full paired data file\n",
    "    - Write new dataset .txt file\n",
    "\n",
    "## References\n",
    "- elevation query: https://stackoverflow.com/questions/58350063/obtain-elevation-from-latitude-longitude-coordinates-with-a-simple-python-script\n",
    "- lamda functions: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "- apply on Nulls: https://stackoverflow.com/questions/26614465/python-pandas-apply-function-if-a-column-value-is-not-null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib\n",
    "import urllib3\n",
    "import time\n",
    "import gzip\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if you are running 32-bit Python (output would be False)\n",
    "# 32-bit Python could result in Memory Error when reading in large dataset\n",
    "import sys\n",
    "sys.maxsize > 2**32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set File Paths and Runtime Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to classify the name \n",
    "time_now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# File paths and script options\n",
    "PATH_TO_PAIRED_DATA = \"../data/Cloud_Data/1.1-circles_to_many_stations_usa_weather_data_20200710111406.txt\"\n",
    "PATH_TO_CLEAN_CBC_DATA = \"../data/Cloud_Data/1.0-rec-initial-data-cleaning.txt\"\n",
    "PATH_TO_OFFLINE_ELEVATION_DATA = \"../data/Cloud_Data/1.2.1-ijd-fetch-circle-elevations-OFFLINE.csv\"\n",
    "PATH_TO_LOG_FILE = \"../data/Cloud_Data/1.2-ijd-fetch_circle_elevations_\"+time_now+\".log\"\n",
    "\n",
    "# option to pull offline elevation data from the /attic instead of running the queries\n",
    "get_offline_data = False\n",
    "\n",
    "# option to run a simple test of the query; only 1000 rows are queried instead of full dataset\n",
    "test_query = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Clean Data to Create a List of Unique Locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90411, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcdebaca/.pyenv/versions/funhacks371/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (29,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>max_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>max_snow_imperial</th>\n",
       "      <th>min_temp_imperial</th>\n",
       "      <th>max_temp_imperial</th>\n",
       "      <th>min_temp_metric</th>\n",
       "      <th>max_temp_metric</th>\n",
       "      <th>min_wind_metric</th>\n",
       "      <th>max_wind_metric</th>\n",
       "      <th>min_wind_imperial</th>\n",
       "      <th>max_wind_imperial</th>\n",
       "      <th>ui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pacific Grove</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>36.616700</td>\n",
       "      <td>-121.916700</td>\n",
       "      <td>1901</td>\n",
       "      <td>1900-12-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.6167-121.9167_1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pueblo</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>38.175251</td>\n",
       "      <td>-104.519575</td>\n",
       "      <td>1901</td>\n",
       "      <td>1900-12-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.175251-104.519575_1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>US-CT</td>\n",
       "      <td>41.671800</td>\n",
       "      <td>-72.949500</td>\n",
       "      <td>1901</td>\n",
       "      <td>1900-12-25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6718-72.9495_1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norwalk</td>\n",
       "      <td>US-CT</td>\n",
       "      <td>41.116700</td>\n",
       "      <td>-73.400000</td>\n",
       "      <td>1901</td>\n",
       "      <td>1900-12-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.1167-73.4_1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glen Ellyn</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>41.883300</td>\n",
       "      <td>-88.066700</td>\n",
       "      <td>1901</td>\n",
       "      <td>1900-12-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.8833-88.0667_1901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     circle_name country_state        lat         lon  count_year  count_date  \\\n",
       "0  Pacific Grove         US-CA  36.616700 -121.916700        1901  1900-12-25   \n",
       "1         Pueblo         US-CO  38.175251 -104.519575        1901  1900-12-25   \n",
       "2        Bristol         US-CT  41.671800  -72.949500        1901  1900-12-25   \n",
       "3        Norwalk         US-CT  41.116700  -73.400000        1901  1900-12-25   \n",
       "4     Glen Ellyn         US-IL  41.883300  -88.066700        1901  1900-12-25   \n",
       "\n",
       "   n_field_counters  n_feeder_counters  min_field_parties  max_field_parties  \\\n",
       "0               1.0                NaN                NaN                NaN   \n",
       "1               1.0                NaN                NaN                NaN   \n",
       "2               2.0                NaN                NaN                NaN   \n",
       "3               1.0                NaN                NaN                NaN   \n",
       "4               1.0                NaN                NaN                NaN   \n",
       "\n",
       "   ...  max_snow_imperial  min_temp_imperial  max_temp_imperial  \\\n",
       "0  ...                NaN                NaN                NaN   \n",
       "1  ...                NaN                NaN                NaN   \n",
       "2  ...                NaN                NaN                NaN   \n",
       "3  ...                NaN                NaN                NaN   \n",
       "4  ...                NaN                NaN                NaN   \n",
       "\n",
       "   min_temp_metric  max_temp_metric min_wind_metric  max_wind_metric  \\\n",
       "0              NaN              NaN             NaN              NaN   \n",
       "1              NaN              NaN             NaN              NaN   \n",
       "2              NaN              NaN             NaN              NaN   \n",
       "3              NaN              NaN             NaN              NaN   \n",
       "4              NaN              NaN             NaN              NaN   \n",
       "\n",
       "   min_wind_imperial  max_wind_imperial                         ui  \n",
       "0                NaN                NaN      36.6167-121.9167_1901  \n",
       "1                NaN                NaN  38.175251-104.519575_1901  \n",
       "2                NaN                NaN       41.6718-72.9495_1901  \n",
       "3                NaN                NaN          41.1167-73.4_1901  \n",
       "4                NaN                NaN       41.8833-88.0667_1901  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_csv(PATH_TO_CLEAN_CBC_DATA, encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "\n",
    "print(clean_data.shape)\n",
    "\n",
    "clean_data['ui'].nunique()\n",
    "\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique Lat Lon combos in the dataset is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Temportary String to Merge on\n",
    "clean_data['temp_key_str'] = round(clean_data['lat'],3).astype(str) + round(clean_data['lon'],3).astype(str)\n",
    "    \n",
    "print(\"The number of unique Lat Lon combos in the dataset is: \")   \n",
    "clean_data['temp_key_str'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90411, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_unique = clean_data[[\"lat\", \"lon\", \"temp_key_str\"]]\n",
    "clean_data_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4584, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_unique = clean_data_unique.drop_duplicates(\"temp_key_str\")\n",
    "clean_data_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp_key_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.616700</td>\n",
       "      <td>-121.916700</td>\n",
       "      <td>36.617-121.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.175251</td>\n",
       "      <td>-104.519575</td>\n",
       "      <td>38.175-104.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.671800</td>\n",
       "      <td>-72.949500</td>\n",
       "      <td>41.672-72.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.116700</td>\n",
       "      <td>-73.400000</td>\n",
       "      <td>41.117-73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.883300</td>\n",
       "      <td>-88.066700</td>\n",
       "      <td>41.883-88.067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon    temp_key_str\n",
       "0  36.616700 -121.916700  36.617-121.917\n",
       "1  38.175251 -104.519575   38.175-104.52\n",
       "2  41.671800  -72.949500    41.672-72.95\n",
       "3  41.116700  -73.400000     41.117-73.4\n",
       "4  41.883300  -88.066700   41.883-88.067"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Data if nessasary \n",
    "# clean_data_unique.to_csv('../data/Cloud_data/1.2-ijd-fetch-circle-elevations_usgs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not get_offline_data:\n",
    "#     logging.basicConfig(filename=PATH_TO_LOG_FILE, \n",
    "#                         filemode='w', \n",
    "#                         format='%(message)s', \n",
    "#                         level=logging.INFO)\n",
    "#     logging.info('This log file shows the row index, lat, lon\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to make a remote request to the USGS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remote_request(url: str, params: dict):\n",
    "    \"\"\"\n",
    "    Makes the remote request\n",
    "    Continues making attempts until it succeeds\n",
    "    \"\"\"\n",
    "\n",
    "    count = 1\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get((url + urllib.parse.urlencode(params)))\n",
    "            time.sleep(1)\n",
    "        except (OSError, urllib3.exceptions.ProtocolError) as error:\n",
    "            logging.info('\\n')\n",
    "            logging.info('*' * 20, 'Error Occured', '*' * 20)\n",
    "            logging.info(f'Number of tries: {count}')\n",
    "            logging.info(f'URL: {url}')\n",
    "            logging.info(error)\n",
    "            logging.info('\\n')\n",
    "            count += 1\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to supply inputs to the remote request and return the elevation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevation_function(x):\n",
    "    \"\"\"\n",
    "    x - longitude\n",
    "    y - latitude\n",
    "    returns elevation in meters\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://nationalmap.gov/epqs/pqs.php?'\n",
    "    params = {'x': x[1],\n",
    "              'y': x[0],\n",
    "              'units': 'Meters',\n",
    "              'output': 'json'}\n",
    "    logging.info(str(x.name)+'\\t\\t'+str(x[0])+'\\t\\t'+str(x[1]))   # print row index, lat, lon\n",
    "    result = make_remote_request(url, params)\n",
    "    \n",
    "    return result.json()['USGS_Elevation_Point_Query_Service']['Elevation_Query']['Elevation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data From USGS for the unique Lat Lon Locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat                    36.6167\n",
      "lon                   -121.917\n",
      "temp_key_str    36.617-121.917\n",
      "circle_elev                NaN\n",
      "Name: 0, dtype: object\n",
      "lat                   38.1753\n",
      "lon                   -104.52\n",
      "temp_key_str    38.175-104.52\n",
      "circle_elev               NaN\n",
      "Name: 1, dtype: object\n",
      "lat                  41.6718\n",
      "lon                 -72.9495\n",
      "temp_key_str    41.672-72.95\n",
      "circle_elev              NaN\n",
      "Name: 2, dtype: object\n",
      "lat                 41.1167\n",
      "lon                   -73.4\n",
      "temp_key_str    41.117-73.4\n",
      "circle_elev             NaN\n",
      "Name: 3, dtype: object\n",
      "lat                   41.8833\n",
      "lon                  -88.0667\n",
      "temp_key_str    41.883-88.067\n",
      "circle_elev               NaN\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if not get_offline_data:\n",
    "#     temp = clean_data_unique[['lat', 'lon']]\n",
    "\n",
    "    clean_data_unique.loc[:, 'circle_elev'] = np.nan\n",
    "    clean_data_unique.head(50)\n",
    "\n",
    "    testing_count = 0\n",
    "\n",
    "    for index, row in clean_data_unique.iterrows():\n",
    "\n",
    "        try:\n",
    "            print(row['temp_key_str'])\n",
    "            # combination of apply() function and lambda() function, only on nulls (see reference links above)\n",
    "            clean_data_unique.loc[index, 'circle_elev'] = elevation_function(row[['lat', 'lon']])\n",
    "        except:\n",
    "            print(\"Exception occurred:\")\n",
    "            print(row['temp_key_str'])        \n",
    "            clean_data_unique.loc[index, 'circle_elev'] = np.nan\n",
    "            continue\n",
    "\n",
    "        if test_query:\n",
    "            testing_count = testing_count + 1\n",
    "            if testing_count >= 5:\n",
    "                break\n",
    "                \n",
    "        time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the result this is: 4584\n",
      "The length of the unique lat lons in the clean data was: (4584, 4)\n",
      "The number of elivations that got an error was: 4579\n"
     ]
    }
   ],
   "source": [
    "# check on the results \n",
    "if not get_offline_data:\n",
    "    print(\"The number of elivations that got an NAN is: \" + str(clean_data_unique['circle_elev'].isna().sum()))\n",
    "    print(clean_data_unique['circle_elev'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the result list as circle_elev\n",
    "if not get_offline_data:\n",
    "    clean_data_unique[\"circle_elev\"] = res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as the offline data\n",
    "# if not get_offline_data:\n",
    "#     clean_data_unique.to_csv('../data/Cloud_Data/1.2.1-ijd-fetch-circle-elevations-OFFLINE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in the data with the Paired dataset. Use offline data for Merge is the variable get_offline_data above is True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcdebaca/.pyenv/versions/funhacks371/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (64,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the paired datafram is: (127174, 66)\n",
      "The number of unique latlon combos is 3500\n"
     ]
    }
   ],
   "source": [
    "# Load in the full dataset \n",
    "paired_df = pd.read_csv(PATH_TO_PAIRED_DATA, encoding = \"ISO-8859-1\", compression='gzip', sep=\"\\t\")\n",
    "\n",
    "print(\"The shape of the paired datafram is: \" + str(paired_df.shape))\n",
    "\n",
    "# Create a key for the paired data to merge on \n",
    "paired_df['temp_key_str'] = paired_df['lat'].astype(str) + paired_df['lon'].astype(str)\n",
    "\n",
    "paired_df['temp_key_str'] = round(paired_df['lat'],3).astype(str) + round(paired_df['lon'],3).astype(str)\n",
    "\n",
    "# Count the number of unique\n",
    "print(\"The number of unique latlon combos is \" + str(paired_df[\"temp_key_str\"].nunique()))\n",
    "\n",
    "\n",
    "# Merge on either the clean data collected from usgs or offline data\n",
    "if not get_offline_data:\n",
    "    # Merge in on the key \n",
    "    paired_df_ = pd.merge(paired_df, clean_data_unique[['temp_key_str', 'circle_elev']], how=\"left\", left_on=\"temp_key_str\", right_on=\"temp_key_str\")\n",
    "\n",
    "else:\n",
    "    offline_data = pd.read_csv(PATH_TO_OFFLINE_ELEVATION_DATA)\n",
    "    # Merge in on the key \n",
    "    paired_df_ = pd.merge(paired_df, offline_data[['temp_key_str', 'circle_elev']], how=\"left\", left_on=\"temp_key_str\", right_on=\"temp_key_str\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the merge \n",
    "print(\"The shape of the merged data is : \" + str(paired_df_.shape))\n",
    "print(\"The number of NAs in the merged data: \" + str(paired_df_['circle_elev'].isna().sum()))\n",
    "print(\"The number of circles with %s:\" % 'circle_elev' + str(paired_df_.shape[0] - paired_df_['circle_elev'].isna().sum()))\n",
    "print(\"Value Counts\")\n",
    "print(paired_df_['circle_elev'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_df_.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screen Elevation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad elevation values\n",
    "paired_df_.loc[paired_df_['circle_elev'] < -10000.0, 'circle_elev'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_df_[['lat', 'lon', 'count_date', 'circle_elev']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of elevations\n",
    "paired_df_.hist(column='circle_elev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same number of rows? Should be 109390\n",
    "len(paired_df_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe on existing index\n",
    "paired_df_.sort_values(['ui'], ascending=[True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the temp key \n",
    "# Drop the temportary key \n",
    "paired_df_ = paired_df_.drop(\"temp_key_str\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEED A NEW WAY TO DO THIS TEST \n",
    "if get_offline_data:\n",
    "    print('If from an offline source, check to make sure circle elevations are not being lost during merge:\\n')\n",
    "    print('NA in Merged:\\n', paired_df_['circle_elev'].isna().value_counts())\n",
    "    print('\\n')\n",
    "    print('NA in Offline:\\n', offline_data['circle_elev'].isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing elevations:')\n",
    "paired_df_['circle_elev'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How many elevations at sea level?')\n",
    "paired_df_.loc[paired_df_['circle_elev'] == 0.0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But First Some QA checks (Should be checked against the input file and previous notebooks)\n",
    "paired_df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_df_['ui'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_df_.to_csv(\"../data/Cloud_Data/1.2.1-ijd-fetch-circle-elevations_\"+time_now+\".txt\", \n",
    "                     sep='\\t', \n",
    "                     compression='gzip',\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

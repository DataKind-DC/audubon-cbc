{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Unknown\n",
    "## Creating a DB View to query ALL NOAA stations for various years\n",
    "The below notebook creates a DB View in your Google BigQuery project. A view is a prepackaged query that does not take up space in your DB. The query is a UNION ALL over the years selected as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "project = 'fjvr-testing' # Change this project to your \n",
    "source_dataset_id = 'audubon_cdc'\n",
    "# source_table_id = 'us_states'\n",
    "shared_dataset_ref = client.dataset(source_dataset_id)\n",
    "\n",
    "# This is the parameter used to create the years that will go into the view\n",
    "year = 1900\n",
    "\n",
    "# The name of the view in our DB\n",
    "view_ref = shared_dataset_ref.table(\"noaa_from_\" + str(year) + \"_to_present\")\n",
    "view = bigquery.Table(view_ref)\n",
    "\n",
    "# The string that will contain the SQL we will use to create our view\n",
    "sql_statement_accumulated = \"\"\n",
    "tables_used = []\n",
    "tables = client.list_tables(\"bigquery-public-data.ghcn_d\")\n",
    "\n",
    "# Iterate over all tables in the schema and store the tables we will use in the tables_used array\n",
    "for table in tables:\n",
    "    try:\n",
    "        if int(table.table_id[-4:]) >= year:\n",
    "            tables_used.append(table.table_id)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Iterate over all values in an array and annex to the sql_statement_accumulated\n",
    "for index in range(0,len(tables_used)):\n",
    "    if index == len(tables_used) - 1:\n",
    "        sql_template = 'SELECT * FROM `{}`'\n",
    "        sql_statement_accumulated = sql_statement_accumulated + sql_template.format(\"bigquery-public-data.ghcn_d.\" + str(tables_used[index]))\n",
    "    else:\n",
    "        sql_template = 'SELECT * FROM `{}` UNION ALL '\n",
    "        sql_statement_accumulated = sql_statement_accumulated + sql_template.format(\"bigquery-public-data.ghcn_d.\" + str(tables_used[index]))\n",
    "        \n",
    "\n",
    "# Assiging the SQL to the associated view\n",
    "view.view_query = sql_statement_accumulated\n",
    "view = client.create_table(view)  # API request\n",
    "\n",
    "print(\"Successfully created view at {}\".format(view.full_table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DB View to flatten the data\n",
    "The below notebook creates a DB View in your Google BigQuery project consisting of the flatten data from the union of all data from NOAA stations given the specified year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Conflict",
     "evalue": "409 POST https://bigquery.googleapis.com/bigquery/v2/projects/fjvr-testing/datasets/audubon_cdc/tables: Already Exists: Table fjvr-testing:audubon_cdc.flatten_noaa_from_1900_to_present",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConflict\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f826b4e58689>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# API request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully created view at {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_table_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36mcreate_table\u001b[1;34m(self, table, exists_ok, retry)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_api_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mapi_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_api_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConflict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36m_call_api\u001b[1;34m(self, retry, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[0mon_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m             )\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\cloud\\_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConflict\u001b[0m: 409 POST https://bigquery.googleapis.com/bigquery/v2/projects/fjvr-testing/datasets/audubon_cdc/tables: Already Exists: Table fjvr-testing:audubon_cdc.flatten_noaa_from_1900_to_present"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Query for flattening the data\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "  base.id, \n",
    "  base.date,\n",
    "  stations.name,\n",
    "  stations.state,\n",
    "  temp_min.value as temp_min_value,\n",
    "  temp_max.value as temp_max_value,\n",
    "  precipitation.value as precipitation_value,\n",
    "  temp_avg.value as temp_avg,\n",
    "  snow.value as snow,\n",
    "  snwd.value as snwd\n",
    "\n",
    "FROM {} base\n",
    "LEFT JOIN {} temp_min ON base.id = temp_min.id AND base.date = temp_min.date AND temp_min.element = 'TMIN'\n",
    "LEFT JOIN {} temp_max ON base.id = temp_max.id AND base.date = temp_max.date AND temp_max.element = 'TMAX'\n",
    "LEFT JOIN {} precipitation ON base.id = precipitation.id AND base.date = precipitation.date AND precipitation.element = 'PRCP'\n",
    "LEFT JOIN {} temp_avg ON base.id = temp_avg.id AND base.date = temp_avg.date AND temp_avg.element = 'TAVG'\n",
    "LEFT JOIN {} snow ON base.id = snow.id AND base.date = snow.date AND snow.element = 'SNOW'\n",
    "LEFT JOIN {} snwd ON base.id = snwd.id AND base.date = snwd.date AND snwd.element = 'SNWD'\n",
    "\n",
    "INNER JOIN `bigquery-public-data`.ghcn_d.ghcnd_stations stations ON base.id = stations.id\n",
    "\n",
    "ORDER BY base.id, base.date\n",
    "\"\"\"\n",
    "\n",
    "# This is the from clause table we will use in our project. \n",
    "# Please replace `fjvr-testing` with your PROJECT NAME\n",
    "parameter = \"`fjvr-testing`.audubon_cdc.noaa_from_1900_to_present\"\n",
    "# In this statement we replace the {} with the corresponding table parameter\n",
    "query = query.format(parameter,parameter,parameter,parameter,parameter,parameter,parameter)\n",
    "\n",
    "# Name of the view in our DB\n",
    "view_ref = shared_dataset_ref.table(\"flatten_noaa_from_\" + str(year) + \"_to_present\")\n",
    "view = bigquery.Table(view_ref)\n",
    "\n",
    "# Assigning the SQL string to the view query\n",
    "view.view_query = query\n",
    "\n",
    "# Creating the view associated with the query\n",
    "view = client.create_table(view)  # API request\n",
    "\n",
    "print(\"Successfully created view at {}\".format(view.full_table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning circles to weather stations\n",
    "Using a custom table created from uploading the CSV to Big Query (this table is called `cleaned_bird_counts_gstorage`) a join is done with the view that contains the flatten data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Used to classify the name \n",
    "time_now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "client = bigquery.Client()\n",
    "project = 'fjvr-testing'\n",
    "source_dataset_id = 'audubon_cdc'\n",
    "# source_table_id = 'us_states'\n",
    "shared_dataset_ref = client.dataset(source_dataset_id)\n",
    "\n",
    "query = \"\"\"\n",
    "WITH circles_hash as (SELECT x.*, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 4) as geohash_circle, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 7) as circle_id\n",
    "\n",
    "FROM `fjvr-testing.audubon_cdc.cleaned_bird_counts_gstorage` x),\n",
    "\n",
    "stations_hash as (SELECT y.*, ST_GEOHASH(ST_GEOGPOINT(y.longitude,y.latitude),4) as geohash_station FROM `bigquery-public-data`.ghcn_d.ghcnd_stations y),\n",
    "\n",
    "circle_with_matched_stations as (SELECT * FROM circles_hash x INNER JOIN stations_hash y ON x.geohash_circle = y.geohash_station)\n",
    "\n",
    "SELECT x.*, y.temp_min_value,y.temp_max_value,y.precipitation_value,y.temp_avg,y.snow,y.snwd\n",
    "\n",
    "FROM circle_with_matched_stations x\n",
    "LEFT JOIN `fjvr-testing.audubon_cdc.flatten_noaa_from_1900_to_present` y ON x.id = y.id AND x.count_date = y.date\n",
    "\n",
    "ORDER BY circle_id DESC,count_date ASC \"\"\"\n",
    "\n",
    "# Queries BigQuery public data set and creates a new dataframe object\n",
    "df_circles_to_stations_weather_data = client.query(query).to_dataframe()\n",
    "\n",
    "# Saving stations in csv COMPRESSED IN GZIP!!!\n",
    "df_circles_to_stations_weather_data.to_csv(r'circles_to_stations_weather_data_' + str(time_now) +  '.csv', compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed__0</th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>gsn_flag</th>\n",
       "      <th>hcn_crn_flag</th>\n",
       "      <th>wmoid</th>\n",
       "      <th>geohash_station</th>\n",
       "      <th>temp_min_value</th>\n",
       "      <th>temp_max_value</th>\n",
       "      <th>precipitation_value</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28806</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1977</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28806</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1977</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30036</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1978</td>\n",
       "      <td>1977-12-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30036</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1978</td>\n",
       "      <td>1977-12-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31321</td>\n",
       "      <td>Amchitka Island</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>51.409713</td>\n",
       "      <td>179.284881</td>\n",
       "      <td>1979</td>\n",
       "      <td>1978-12-30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>zcpk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed__0      circle_name country_state        lat         lon  \\\n",
       "0       28806  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "1       28806  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "2       30036  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "3       30036  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "4       31321  Amchitka Island         US-AK  51.409713  179.284881   \n",
       "\n",
       "   count_year  count_date  n_field_counters n_feeder_counters  \\\n",
       "0        1977  1977-01-01               4.0              None   \n",
       "1        1977  1977-01-01               4.0              None   \n",
       "2        1978  1977-12-29               5.0              None   \n",
       "3        1978  1977-12-29               5.0              None   \n",
       "4        1979  1978-12-30               2.0              None   \n",
       "\n",
       "  min_field_parties  ... gsn_flag hcn_crn_flag wmoid geohash_station  \\\n",
       "0              None  ...                         NaN            zcpk   \n",
       "1              None  ...                         NaN            zcpk   \n",
       "2              None  ...                         NaN            zcpk   \n",
       "3              None  ...                         NaN            zcpk   \n",
       "4              None  ...                         NaN            zcpk   \n",
       "\n",
       "  temp_min_value temp_max_value precipitation_value temp_avg snow snwd  \n",
       "0            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "1            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "2            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "3            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "4            NaN            NaN                 NaN      NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_circles_to_stations_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ezs42\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#!pip install python-geohash\n",
    "\n",
    "import Geohash as ph\n",
    "\n",
    "print(ph.encode(42.6,-5.6, precision=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "record_count = len(df_circles_to_stations_weather_data.index)\n",
    "print(record_count)\n",
    "\n",
    "# record_count = record_count.astype(np.int32)\n",
    "\n",
    "# print(\"Total number of records: \" + record_count)\n",
    "\n",
    "temp_min_nas = df_circles_to_stations_weather_data.temp_min_value.isna().sum()\n",
    "print(\"Missing min temperature: \" + str(temp_min_nas))\n",
    "print('Missing min temperature(%): ', round(temp_avg_nas/float(len(df_circles_to_stations_weather_data))*100,2),'%')\n",
    "\n",
    "temp_avg_nas = df_circles_to_stations_weather_data.temp_avg.isna().sum()\n",
    "print(\"Missing avg temperature: \" + str(temp_avg_nas))\n",
    "temp_avg_nas = df_circles_to_stations_weather_data.temp_avg.isna().sum()\n",
    "snow = df_circles_to_stations_weather_data.snow.isna().sum()\n",
    "snow = snow.astype(np.int32)\n",
    "print(snow)\n",
    "# len(df_circles_to_stations_weather_data)\n",
    "# record_length = len(df_circles_to_stations_weather_data)\n",
    "# record_length = record_length.astype(np.int32)\n",
    "# print(\"Total number of records: \" + str(record_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

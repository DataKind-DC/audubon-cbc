{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Circle Elevations\n",
    "### Purpose\n",
    "In this notebook I query the USGS to get elevation data for all of the circles.\n",
    "This notebook addresses some one of the tasks in Github issue #35\n",
    "\n",
    "### Author: \n",
    "Ian Davis\n",
    "### Date: \n",
    "2020-03-31\n",
    "### Update Date: \n",
    "2020-05-03\n",
    "\n",
    "### Inputs \n",
    "1.1-circles_to_many_stations_usa_weather_data_20200424213015.csv - Comma separate file of the Christmas Bird Count and matches to 1 or more NOAA weather stations.\n",
    "- Data Dictonary can be found here: http://www.audubon.org/sites/default/files/documents/cbc_report_field_definitions_2013.pdf\n",
    "1.2-ijd-fetch-circle-elevations-OFFLINE.csv - Previously generated elevation data. This file will be used when you want to get the elevation data from an offline source and aoivd 100,000+ queries.\n",
    "\n",
    "### Output Files\n",
    "1.2-ijd-fetch-circle-elevations_20200502155633.csv - Only 1 column is added to the dataset, 'circle_elev'. This column is the elevation in meters for a given latitude and longitude of the circle centroid.\n",
    "\n",
    "## Steps or Proceedures in the notebook \n",
    "- Set runtime options\n",
    "    - Set option to retrieve elevations from offline source, or through the USGS queries\n",
    "    - Set option to only test the USGS query (NOTE: running the query function for the whole dataset will take 24+ hours)\n",
    "- Create a function to make a remote request to the USGS API\n",
    "- Create a function to supply inputs to the remote request and return the elevation value\n",
    "- Main sequence\n",
    "    - Read in dataset\n",
    "    - Create circl_elev column\n",
    "    - Loop through the dataset in chunks of 10000 to get elevation data\n",
    "    - (Optional) Retrieve elevations from offline data source instead of queries\n",
    "    - Write new dataset .txt file\n",
    "\n",
    "## References\n",
    "- elevation query: https://stackoverflow.com/questions/58350063/obtain-elevation-from-latitude-longitude-coordinates-with-a-simple-python-script\n",
    "- lamda functions: https://thispointer.com/python-how-to-use-if-else-elif-in-lambda-functions/\n",
    "- apply on Nulls: https://stackoverflow.com/questions/26614465/python-pandas-apply-function-if-a-column-value-is-not-null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib\n",
    "import urllib3\n",
    "import time\n",
    "import gzip\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if you are running 32-bit Python (output would be False)\n",
    "# 32-bit Python could result in Memory Error when reading in large dataset\n",
    "import sys\n",
    "sys.maxsize > 2**32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set File Paths and Runtime Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to classify the name \n",
    "time_now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# File paths and script options\n",
    "PATH_TO_PAIRED_DATA = \"../data/Cloud_Data/1.1-circles_to_many_stations_usa_weather_data_20200617021358.txt\"\n",
    "PATH_TO_OFFLINE_ELEVATION_DATA = \"../data/Cloud_Data/1.2-ijd-fetch-circle-elevations-OFFLINE.csv\"\n",
    "PATH_TO_LOG_FILE = \"../data/Cloud_Data/1.2-ijd-fetch_circle_elevations_\"+time_now+\".log\"\n",
    "\n",
    "# option to pull offline elevation data from the /attic instead of running the queries\n",
    "get_offline_data = True\n",
    "\n",
    "# option to run a simple test of the query; only 1000 rows are queried instead of full dataset\n",
    "test_query = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not get_offline_data:\n",
    "    logging.basicConfig(filename=PATH_TO_LOG_FILE, \n",
    "                        filemode='w', \n",
    "                        format='%(message)s', \n",
    "                        level=logging.INFO)\n",
    "    logging.info('This log file shows the row index, lat, lon\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to make a remote request to the USGS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remote_request(url: str, params: dict):\n",
    "    \"\"\"\n",
    "    Makes the remote request\n",
    "    Continues making attempts until it succeeds\n",
    "    \"\"\"\n",
    "\n",
    "    count = 1\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get((url + urllib.parse.urlencode(params)))\n",
    "            time.sleep(1)\n",
    "        except (OSError, urllib3.exceptions.ProtocolError) as error:\n",
    "            logging.info('\\n')\n",
    "            logging.info('*' * 20, 'Error Occured', '*' * 20)\n",
    "            logging.info(f'Number of tries: {count}')\n",
    "            logging.info(f'URL: {url}')\n",
    "            logging.info(error)\n",
    "            logging.info('\\n')\n",
    "            count += 1\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to supply inputs to the remote request and return the elevation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevation_function(x):\n",
    "    \"\"\"\n",
    "    x - longitude\n",
    "    y - latitude\n",
    "    returns elevation in meters\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://nationalmap.gov/epqs/pqs.php?'\n",
    "    params = {'x': x[1],\n",
    "              'y': x[0],\n",
    "              'units': 'Meters',\n",
    "              'output': 'json'}\n",
    "    logging.info(str(x.name)+'\\t\\t'+str(x[0])+'\\t\\t'+str(x[1]))   # print row index, lat, lon\n",
    "    result = make_remote_request(url, params)\n",
    "    \n",
    "    return result.json()['USGS_Elevation_Point_Query_Service']['Elevation_Query']['Elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = pd.read_csv(PATH_TO_PAIRED_DATA, chunksize=1000, compression='gzip', encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops to Query the USGS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean to skip loop of queries and just pull elevation data from the \"attic\"\n",
    "if not get_offline_data:\n",
    "    \n",
    "    # load paired data file\n",
    "    #data_iterator = pd.read_csv(PATH_TO_TEMP_DATA, chunksize=1000, encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "    data_iterator = pd.read_csv(PATH_TO_PAIRED_DATA, chunksize=1000, compression='gzip', encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "        \n",
    "    chunk_list = []  \n",
    "    \n",
    "    # Each chunk is in dataframe format\n",
    "    for data_chunk in data_iterator:\n",
    "        # create elevation column\n",
    "        data_chunk.loc[:, 'circle_elev'] = np.nan\n",
    "        \n",
    "        # initial list of indices which are missing elevations\n",
    "        missing = data_chunk.loc[data_chunk['circle_elev'].isnull()].index\n",
    "    \n",
    "        # while loop to go over the dataset chunk times in the event that query requests fail\n",
    "        cnt=0 # counter to break while loop after\n",
    "        while len(missing) > 0:\n",
    "            if cnt == 5: break # exit while loop\n",
    "            cnt+=1\n",
    "            logging.info('while counter: '+str(cnt))\n",
    "        \n",
    "            try:\n",
    "                # combination of apply() function and lambda() function, only on nulls (see reference links above)\n",
    "                data_chunk.loc[:, 'circle_elev'] = data_chunk.loc[:, ['lat', 'lon', 'circle_elev']].apply(lambda x: elevation_function(x[0:2]) if(pd.isnull(x[2])) else x[2], axis=1)\n",
    "            except:\n",
    "                # on occasion query completely fails and crashes the function call\n",
    "                # problem is the stack prints to the notebook\n",
    "                # https://gist.github.com/wassname/d17325f36c36fa663dd7de3c09a55e74\n",
    "                #logging.error(\"Exception occurred\", exc_info=True)\n",
    "                logging.info(\"Exception occurred\")\n",
    "                continue\n",
    "    \n",
    "            # get new list of missing indices\n",
    "            missing = data_chunk.loc[data_chunk['circle_elev'].isnull()].index\n",
    "            # break the loop if there are no missing elevations\n",
    "            if len(missing) == 0: break\n",
    "        \n",
    "        # Append data chunk with elevation data to combined list\n",
    "        chunk_list.append(data_chunk)\n",
    "        \n",
    "        # Convert combined list into dataframe\n",
    "        filtered_data = pd.concat(chunk_list)\n",
    "        # Intermediate writes to .csv file so work is not lost in the event of code failure\n",
    "        filtered_data.to_csv(\"../data/Cloud_Data/1.2-ijd-fetch-circle-elevations_INT.csv\", sep=',', index=False)\n",
    "        del(filtered_data)\n",
    "        \n",
    "        # If just running a test, break the loop\n",
    "        if test_query: break\n",
    "    \n",
    "    # Convert combined list into dataframe\n",
    "    filtered_data = pd.concat(chunk_list)\n",
    "    \n",
    "    # close log file\n",
    "    #log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Get Elevation Data from Offline Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chunks should be the same length after merge.\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcdebaca/.pyenv/versions/funhacks371/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (64,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcdebaca/.pyenv/versions/funhacks371/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (10000, 66)\n",
      "Chunk Length After:  (10000, 67)\n",
      "Chunk Length Before:  (8957, 66)\n",
      "Chunk Length After:  (8957, 67)\n"
     ]
    }
   ],
   "source": [
    "if get_offline_data:\n",
    "    # load offline data file\n",
    "    offline_data = pd.read_csv(PATH_TO_OFFLINE_ELEVATION_DATA)\n",
    "    \n",
    "    # convert count_date to string or merge won't match them properly \n",
    "    offline_data['count_date'] = pd.to_datetime(offline_data['count_date'])\n",
    "    \n",
    "    # round the latitude and longitudes to 4 digits\n",
    "    offline_data['lat'] = offline_data['lat'].round(3)\n",
    "    offline_data['lon'] = offline_data['lon'].round(3)\n",
    "    \n",
    "    # load paired data file\n",
    "    #data_iterator = pd.read_csv(PATH_TO_TEMP_DATA, chunksize=10000, encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "    data_iterator = pd.read_csv(PATH_TO_PAIRED_DATA, \n",
    "                                compression='gzip', \n",
    "                                chunksize=10000,\n",
    "                               encoding = \"ISO-8859-1\", \n",
    "                                sep=\"\\t\")\n",
    "        \n",
    "    chunk_list = []  \n",
    "\n",
    "    # Each chunk is in dataframe format\n",
    "    print('The chunks should be the same length after merge.')\n",
    "    for data_chunk in data_iterator:\n",
    "        data_chunk['count_date'] = pd.to_datetime(data_chunk['count_date'])\n",
    "        data_chunk['lat'] = data_chunk['lat'].round(3)\n",
    "        data_chunk['lon'] = data_chunk['lon'].round(3)\n",
    "        filtered_chunk = pd.merge(data_chunk, \n",
    "                                  offline_data[['lat', 'lon', 'count_date', 'count_year', 'id', 'circle_elev']], \n",
    "                                  on=['lat', 'lon', 'count_date', 'count_year', 'id'],\n",
    "                                  how='left',\n",
    "                                  copy=False)\n",
    "        chunk_list.append(filtered_chunk)\n",
    "        print('Chunk Length Before: ', data_chunk.shape)\n",
    "        print('Chunk Length After: ', filtered_chunk.shape)\n",
    "\n",
    "    \n",
    "    filtered_data = pd.concat(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates in offline data\n",
    "if get_offline_data:\n",
    "    offline_data.duplicated(subset=['lat', 'lon', 'count_date', 'count_year', 'id']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any duplicates in the data chunk?\n",
    "if get_offline_data:\n",
    "    data_chunk.duplicated(subset=['lat', 'lon', 'count_date', 'count_year', 'id']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screen Elevation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure elevations are the float\n",
    "filtered_data = pd.concat(chunk_list)\n",
    "filtered_data.loc[:, 'circle_elev'] = filtered_data.loc[:, 'circle_elev'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad elevation values\n",
    "filtered_data.loc[filtered_data['circle_elev'] < -10000.0, 'circle_elev'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_date</th>\n",
       "      <th>circle_elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.410</td>\n",
       "      <td>179.285</td>\n",
       "      <td>1979-12-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.410</td>\n",
       "      <td>179.285</td>\n",
       "      <td>1992-12-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2011-12-28</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2014-12-14</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46.913</td>\n",
       "      <td>-67.947</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>176.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1969-12-29</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1970-12-30</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1971-12-19</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1972-12-30</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1973-12-30</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1974-12-28</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1975-12-28</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1976-12-19</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1977-12-18</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1978-12-17</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1979-12-16</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1980-12-20</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1981-12-20</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1982-12-19</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1983-12-18</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1984-12-16</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1985-12-21</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1986-12-21</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1987-12-20</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1988-12-17</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1989-12-17</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1990-12-16</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1991-12-15</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1992-12-20</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1994-01-02</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>1996-12-28</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2001-12-30</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2002-12-28</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2003-12-27</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2004-12-19</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2006-12-30</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2007-12-29</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2008-12-27</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2013-12-28</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>46.681</td>\n",
       "      <td>-68.015</td>\n",
       "      <td>2013-12-28</td>\n",
       "      <td>138.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lat      lon count_date  circle_elev\n",
       "0   51.410  179.285 1979-12-18          NaN\n",
       "1   51.410  179.285 1992-12-20          NaN\n",
       "2   46.913  -67.947 2011-12-28       176.31\n",
       "3   46.913  -67.947 2012-12-29       176.31\n",
       "4   46.913  -67.947 2014-01-01       176.31\n",
       "5   46.913  -67.947 2014-12-14       176.31\n",
       "6   46.913  -67.947 2015-12-19       176.31\n",
       "7   46.913  -67.947 2016-12-17       176.31\n",
       "8   46.913  -67.947 2017-12-16       176.31\n",
       "9   46.681  -68.015 1969-12-29       138.62\n",
       "10  46.681  -68.015 1970-12-30       138.62\n",
       "11  46.681  -68.015 1971-12-19       138.62\n",
       "12  46.681  -68.015 1972-12-30       138.62\n",
       "13  46.681  -68.015 1973-12-30       138.62\n",
       "14  46.681  -68.015 1974-12-28       138.62\n",
       "15  46.681  -68.015 1975-12-28       138.62\n",
       "16  46.681  -68.015 1976-12-19       138.62\n",
       "17  46.681  -68.015 1977-12-18       138.62\n",
       "18  46.681  -68.015 1978-12-17       138.62\n",
       "19  46.681  -68.015 1979-12-16       138.62\n",
       "20  46.681  -68.015 1980-12-20       138.62\n",
       "21  46.681  -68.015 1981-12-20       138.62\n",
       "22  46.681  -68.015 1982-12-19       138.62\n",
       "23  46.681  -68.015 1983-12-18       138.62\n",
       "24  46.681  -68.015 1984-12-16       138.62\n",
       "25  46.681  -68.015 1985-12-21       138.62\n",
       "26  46.681  -68.015 1986-12-21       138.62\n",
       "27  46.681  -68.015 1987-12-20       138.62\n",
       "28  46.681  -68.015 1988-12-17       138.62\n",
       "29  46.681  -68.015 1989-12-17       138.62\n",
       "30  46.681  -68.015 1990-12-16       138.62\n",
       "31  46.681  -68.015 1991-12-15       138.62\n",
       "32  46.681  -68.015 1992-12-20       138.62\n",
       "33  46.681  -68.015 1994-01-02       138.62\n",
       "34  46.681  -68.015 1994-12-31       138.62\n",
       "35  46.681  -68.015 1996-12-28       138.62\n",
       "36  46.681  -68.015 2001-12-30       138.62\n",
       "37  46.681  -68.015 2002-12-28       138.62\n",
       "38  46.681  -68.015 2003-12-27       138.62\n",
       "39  46.681  -68.015 2004-12-19       138.62\n",
       "40  46.681  -68.015 2005-12-31       138.62\n",
       "41  46.681  -68.015 2006-12-30       138.62\n",
       "42  46.681  -68.015 2007-12-29       138.62\n",
       "43  46.681  -68.015 2008-12-27       138.62\n",
       "44  46.681  -68.015 2010-01-02       138.62\n",
       "45  46.681  -68.015 2011-01-01       138.62\n",
       "46  46.681  -68.015 2011-12-31       138.62\n",
       "47  46.681  -68.015 2013-01-01       138.62\n",
       "48  46.681  -68.015 2013-12-28       138.62\n",
       "49  46.681  -68.015 2013-12-28       138.62"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[['lat', 'lon', 'count_date', 'circle_elev']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x116881e48>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create histogram of elevations\n",
    "filtered_data.hist(column='circle_elev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108957"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same number of rows? Should be 109390\n",
    "len(filtered_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnamed columns\n",
    "# they were likely index columns auto-generated by pandas and then written to csv files, unintentionally\n",
    "filtered_data = filtered_data.loc[:, ~filtered_data.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe on existing index\n",
    "filtered_data.sort_values(['ui'], ascending=[True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_name</th>\n",
       "      <th>country_state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>count_year</th>\n",
       "      <th>count_date</th>\n",
       "      <th>n_field_counters</th>\n",
       "      <th>n_feeder_counters</th>\n",
       "      <th>min_field_parties</th>\n",
       "      <th>max_field_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_max_value</th>\n",
       "      <th>precipitation_value</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "      <th>am_rain</th>\n",
       "      <th>pm_rain</th>\n",
       "      <th>am_snow</th>\n",
       "      <th>pm_snow</th>\n",
       "      <th>circle_elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>Hawai'i: Volcano</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>19.517</td>\n",
       "      <td>-155.3</td>\n",
       "      <td>1973</td>\n",
       "      <td>1972-12-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>244.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1551.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>Hawai'i: Volcano</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>19.517</td>\n",
       "      <td>-155.3</td>\n",
       "      <td>1973</td>\n",
       "      <td>1972-12-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1551.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6893</th>\n",
       "      <td>Hawai'i: Volcano</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>19.517</td>\n",
       "      <td>-155.3</td>\n",
       "      <td>1973</td>\n",
       "      <td>1972-12-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1551.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>Hawai'i: Volcano</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>19.517</td>\n",
       "      <td>-155.3</td>\n",
       "      <td>1973</td>\n",
       "      <td>1972-12-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>167.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1551.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895</th>\n",
       "      <td>Hawai'i: Volcano</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>19.517</td>\n",
       "      <td>-155.3</td>\n",
       "      <td>1973</td>\n",
       "      <td>1972-12-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1551.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           circle_name country_state     lat    lon  count_year count_date  \\\n",
       "6894  Hawai'i: Volcano         US-HI  19.517 -155.3        1973 1972-12-30   \n",
       "6892  Hawai'i: Volcano         US-HI  19.517 -155.3        1973 1972-12-30   \n",
       "6893  Hawai'i: Volcano         US-HI  19.517 -155.3        1973 1972-12-30   \n",
       "6896  Hawai'i: Volcano         US-HI  19.517 -155.3        1973 1972-12-30   \n",
       "6895  Hawai'i: Volcano         US-HI  19.517 -155.3        1973 1972-12-30   \n",
       "\n",
       "      n_field_counters  n_feeder_counters  min_field_parties  \\\n",
       "6894              14.0                0.0                5.0   \n",
       "6892              14.0                0.0                5.0   \n",
       "6893              14.0                0.0                5.0   \n",
       "6896              14.0                0.0                5.0   \n",
       "6895              14.0                0.0                5.0   \n",
       "\n",
       "      max_field_parties  ...  temp_max_value  precipitation_value  temp_avg  \\\n",
       "6894                5.0  ...           244.0                 18.0       NaN   \n",
       "6892                5.0  ...             NaN                  3.0       NaN   \n",
       "6893                5.0  ...             NaN                  NaN       NaN   \n",
       "6896                5.0  ...           167.0                 10.0       NaN   \n",
       "6895                5.0  ...             NaN                 86.0       NaN   \n",
       "\n",
       "      snow  snwd am_rain  pm_rain  am_snow  pm_snow  circle_elev  \n",
       "6894   0.0   0.0       2        2        3        3      1551.44  \n",
       "6892   0.0   0.0       2        2        3        3      1551.44  \n",
       "6893   0.0   0.0       2        2        3        3      1551.44  \n",
       "6896   0.0   0.0       2        2        3        3      1551.44  \n",
       "6895   0.0   0.0       2        2        3        3      1551.44  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If from an offline source, check to make sure circle elevations are not being lost during merge:\n",
      "\n",
      "NA in Merged:\n",
      " False    108554\n",
      "True        403\n",
      "Name: circle_elev, dtype: int64\n",
      "\n",
      "\n",
      "NA in Offline:\n",
      " False    109224\n",
      "True        166\n",
      "Name: circle_elev, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if get_offline_data:\n",
    "    print('If from an offline source, check to make sure circle elevations are not being lost during merge:\\n')\n",
    "    print('NA in Merged:\\n', filtered_data['circle_elev'].isna().value_counts())\n",
    "    print('\\n')\n",
    "    print('NA in Offline:\\n', offline_data['circle_elev'].isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing elevations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    108554\n",
       "True        403\n",
       "Name: circle_elev, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Missing elevations:')\n",
    "filtered_data['circle_elev'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many elevations at sea level?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1331, 67)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('How many elevations at sea level?')\n",
    "filtered_data.loc[filtered_data['circle_elev'] == 0.0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108957, 67)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#But First Some QA checks (Should be checked against the input file and previous notebooks)\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52740"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['ui'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv(\"../data/Cloud_Data/1.2-ijd-fetch-circle-elevations_\"+time_now+\".txt\", \n",
    "                     sep='\\t', \n",
    "                     compression='gzip',\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

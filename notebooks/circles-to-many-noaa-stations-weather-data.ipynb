{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning circles to weather stations\n",
    "Using a custom table created from uploading the CSV to Big Query (this table is called `cleaned_bird_counts_gstorage`) a join is done with the view that contains the flatten data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9e78c65f5a03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Used to classify the name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtime_now\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d%H%M%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Used to classify the name \n",
    "time_now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "client = bigquery.Client()\n",
    "project = 'fjvr-testing'\n",
    "source_dataset_id = 'audubon_cdc'\n",
    "# source_table_id = 'us_states'\n",
    "shared_dataset_ref = client.dataset(source_dataset_id)\n",
    "\n",
    "query = \"\"\"\n",
    "WITH circles_hash as (SELECT x.*, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 4) as geohash_circle, ST_GEOHASH(ST_GEOGPOINT(x.lon,x.lat), 7) as circle_id\n",
    "\n",
    "FROM `fjvr-testing.audubon_cdc.cleaned_bird_counts_gstorage` x),\n",
    "\n",
    "stations_hash as (SELECT y.*, ST_GEOHASH(ST_GEOGPOINT(y.longitude,y.latitude),4) as geohash_station FROM `bigquery-public-data`.ghcn_d.ghcnd_stations y),\n",
    "\n",
    "circle_with_matched_stations as (SELECT * FROM circles_hash x INNER JOIN stations_hash y ON x.geohash_circle = y.geohash_station)\n",
    "\n",
    "SELECT x.*, y.temp_min_value,y.temp_max_value,y.precipitation_value,y.temp_avg,y.snow,y.snwd\n",
    "\n",
    "FROM circle_with_matched_stations x\n",
    "LEFT JOIN `fjvr-testing.audubon_cdc.flatten_noaa_from_1900_to_present` y ON x.id = y.id AND x.count_date = y.date\n",
    "\n",
    "ORDER BY circle_id DESC,count_date ASC \"\"\"\n",
    "\n",
    "# Queries BigQuery public data set and creates a new dataframe object\n",
    "df_circles_to_stations_weather_data = client.query(query).to_dataframe()\n",
    "\n",
    "# Saving stations in csv COMPRESSED IN GZIP!!!\n",
    "df_circles_to_stations_weather_data.to_csv(r'circles_to_stations_weather_data_' + str(time_now) +  '.csv', compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 records\n",
    "Showing the top 5 records of the data extracted to the query above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circles_to_stations_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on dataset\n",
    "How many records are empty for the various temperature measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "record_count = len(df_circles_to_stations_weather_data.index)\n",
    "print(record_count)\n",
    "\n",
    "# record_count = record_count.astype(np.int32)\n",
    "\n",
    "# print(\"Total number of records: \" + record_count)\n",
    "\n",
    "temp_min_nas = df_circles_to_stations_weather_data.temp_min_value.isna().sum()\n",
    "print(\"Missing min temperature: \" + str(temp_min_nas))\n",
    "print('Missing min temperature(%): ', round(temp_avg_nas/float(len(df_circles_to_stations_weather_data))*100,2),'%')\n",
    "\n",
    "temp_avg_nas = df_circles_to_stations_weather_data.temp_avg.isna().sum()\n",
    "print(\"Missing avg temperature: \" + str(temp_avg_nas))\n",
    "temp_avg_nas = df_circles_to_stations_weather_data.temp_avg.isna().sum()\n",
    "snow = df_circles_to_stations_weather_data.snow.isna().sum()\n",
    "snow = snow.astype(np.int32)\n",
    "print(snow)\n",
    "# len(df_circles_to_stations_weather_data)\n",
    "# record_length = len(df_circles_to_stations_weather_data)\n",
    "# record_length = record_length.astype(np.int32)\n",
    "# print(\"Total number of records: \" + str(record_length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python36764bit5b1c0910026742dfb4573c9ff0b64985"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rain Analysis\n",
    "### Purpose\n",
    "This notebook will look at volunteer trends for reporting rain, adressing the Github issue #54\n",
    "\n",
    "### Author: \n",
    "Hamza El-Saawy\n",
    "### Date: \n",
    "2020-06-14\n",
    "### Update Date: \n",
    "2020-06-14\n",
    "\n",
    "### Inputs \n",
    " - `1.1-circles_to_many_stations_usa_weather_data_20200623005013.txt`\n",
    "\n",
    "### Output Files\n",
    "`2.1-cbc_prcp_1900-2018.csv`: A reduced CBC dataset consisiting of only rain (precipitaion) data and an analysis of that data compared to the NOAA GHCN data\n",
    "\n",
    "## Steps or Proceedures in the notebook \n",
    " - Clean the CBC data\n",
    " - Compare to NOAA data\n",
    " - Make some plots\n",
    "\n",
    "## Where the Data will Be Saved \n",
    "The project Google Drive, at: https://drive.google.com/drive/folders/1Nlj9Nq-_dPFTDbrSDf94XMritWYG6E2I\n",
    "\n",
    "## Notes\n",
    "the flattened NOAA BigQuery drops the `QFLAG` column, so we cannot drop erroneous data and also does not contain the `WT**` `element` values (which can be used alongside the `PRCP` fields to determin precipitation)\n",
    "\n",
    "Additionally, 1.1 drops rows where `temp_min_value`, `temp_max_value`, `temp_avg`, and `snow` are `nan`, but they could have usable values for `[am|pm]_rain`, since it is much easier to simply annotate if weather happened vs taking measurments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the haversine distance formula fromt the script (w/o executing the '__main__' part)\n",
    "%run -ni '../scripts/noaa.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned data set, `1.0-rec-initial-data-cleaning.txt`, drops circles with \"impossible\" temperture, wind, and snow values, which we still find valuable here since we assume that even mistaken/erroneous temp/wind data can still have valuable precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# drop all stations farther than this threshold (meters)\n",
    "#  the farthers is ~36km, with the average being 10km\n",
    "#  16km ~= 10 mi\n",
    "DISTANCE_THRESHOLD = 15000\n",
    "\n",
    "# consider stations to consense on a rain value if a fraction of them or more all have the same reading\n",
    "# at the most abiguous, the fraction will be 0.5, so values are symmetric around 1/2: 0.25 in agreement is the same as 0.75 agreeing on the opposite\n",
    "AGREEMENT_THRESHOLD = 0.75\n",
    "AGREEMENT_THRESHOLD = max(AGREEMENT_THRESHOLD, 1 - AGREEMENT_THRESHOLD)\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/Cloud_Data'\n",
    "RAW_DATA_PATH = os.path.join(DATA_PATH, 'cbc_effort_weather_1900-2018.txt')\n",
    "CLN_DATA_PATH = os.path.join(DATA_PATH, '1.0-rec-initial-data-cleaning.txt')\n",
    "NOAA_DATA_PATH = os.path.join(DATA_PATH, '1.1-circles_to_many_stations_usa_weather_data_20200623005013.txt')\n",
    "CBC_PRCP_PATH = os.path.join(DATA_PATH, 'cbc_prcp_1900-2018.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/anaconda3/envs/audubon/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (29,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/hamza/anaconda3/envs/audubon/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (64,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(RAW_DATA_PATH, encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "clean_data = pd.read_csv(CLN_DATA_PATH, encoding = \"ISO-8859-1\", sep=\"\\t\")\n",
    "noaa_data = pd.read_csv(NOAA_DATA_PATH, encoding = \"ISO-8859-1\", sep=\"\\t\").rename(columns={'lat': 'c_lat', 'lon': 'c_lon', \n",
    "                                                                                           'id': 's_id', 'latitude': 's_lat', 'longitude': 's_lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_data = noaa_data.loc[:, ('count_date',\n",
    "                              'circle_name', 'country_state', 'circle_id', 'c_lat', 'c_lon',\n",
    "                              'am_rain', 'pm_rain',\n",
    "                              's_id', 's_lat', 's_lon',\n",
    "                              'precipitation_value',\n",
    "                             )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.NA preserved int-ness of bools, so they are not converted to floats, and supports three-valued (kleene) logic\n",
    "prcp_data['s_rain'] = np.where(prcp_data.precipitation_value.isna(), pd.NA, prcp_data.precipitation_value > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### volunteer records\n",
    "\n",
    "`[am|pm]_rain` are strings containing `1`:`4`, for heavy, light, none, or unknow rain\n",
    "If the string contains `4`, then -- regardless of observations in that string (e.g. `2,4`) -- it will be marked as `NaN`  \n",
    "If the string contains either `1` or `2` in the am or pm, then there was precipitation that day  \n",
    "If both am and pm are `3`, then there was no precipitation that day  \n",
    "Else, we mark `nan`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for c in ['am_rain', 'pm_rain']:\n",
    "    i = ~prcp_data[c].isna()\n",
    "    prcp_data.loc[i, c] = prcp_data.loc[i, c].astype('int64').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['am_rain', 'pm_rain']:\n",
    "    prcp_data.loc[prcp_data[c].isna(), c] = pd.NA\n",
    "    prcp_data.loc[prcp_data[c].str.contains('4', na=False), c] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_data['c_rain'] = pd.NA\n",
    "\n",
    "prcp_data.loc[(prcp_data.am_rain.str.contains('[12]', na=False) | prcp_data.pm_rain.str.contains('[12]', na=False)), 'c_rain'] = True\n",
    "prcp_data.loc[((prcp_data.am_rain == '3') & (prcp_data.pm_rain == '3')), 'c_rain'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distance between stations and circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_data['distance'] = prcp_data.apply(lambda tt: haversine_formula((tt.c_lat, tt.c_lon), (tt.s_lat, tt.s_lon)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop everything outside of the radius\n",
    "prcp_data.drop(prcp_data[prcp_data.distance > DISTANCE_THRESHOLD].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_data = prcp_data.loc[:, ['count_date', \n",
    "                              'circle_name', 'country_state', 'circle_id', 'c_lat', 'c_lon',\n",
    "                              's_id', 's_lat', 's_lon', 'distance',\n",
    "                              'c_rain', 's_rain',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "undo the left join with the station so each circle/count data occurs once   \n",
    "this is for efficency reasons: i just want to work with the station data, then add in circle data afterwards  \n",
    "(I am assumiong circle is unique for each date: no two circles with different lat/lons have the same id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the circle location information information (no dates)\n",
    "circle_metadata = prcp_data[['circle_name', 'country_state', 'circle_id', 'c_lat', 'c_lon',]].groupby(['circle_id']).agg('first')\n",
    "# circle date and location information along with volunteer data\n",
    "circle_obs = prcp_data[['count_date', 'circle_name', 'country_state', 'circle_id', \n",
    "                        'c_lat', 'c_lon','c_rain']].groupby(['circle_id', 'count_date']).agg('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circle and station multi-index, with only station information\n",
    "station_obs = prcp_data[['count_date', 'circle_id', \n",
    "           's_id', 's_lat', 's_lon', 'distance',\n",
    "           's_rain',]].set_index(['circle_id', 'count_date', 's_id']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = station_obs.groupby(level=['circle_id', 'count_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rain Analysis\n",
    "All the below analyses use the fraction-agreement threshold defined above, and are only for stations within the above-defined distance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rain_calc(dfg):\n",
    "    is_na = dfg.s_rain.isna()\n",
    "    \n",
    "    num = dfg.s_rain.size + 0\n",
    "    num_notna = dfg.s_rain.count() + 0\n",
    "    num_true = dfg.s_rain.sum() + 0\n",
    "\n",
    "    return pd.Series({\n",
    "        # there can be weirdness with boolean not being promoted to ints, so add zero\n",
    "        'num' : num,\n",
    "        'num_notna' : num_notna,\n",
    "        'num_true' : num_true,\n",
    "\n",
    "        'p' : num_true / num_notna if (num_notna > 0) else np.NaN,\n",
    "        # theres a sinister bug where stations present twice for the same circle, so dims are not dropped for `dfg.s_rain[...idxmin()]`\n",
    "        # in that case, the result is a series\n",
    "        # so,force retention as dataframe and this convoluted bs :/\n",
    "        # examples: ('9yuvef2', '2010-12-26'), ('9z70n7m', '2008-12-27'), ('djvyywp', '2013-12-24'), ('dp9mpqu', '2012-12-15'), ('dpe0e5b', '2010-12-26'), ...\n",
    "        'rain_closest' : dfg.loc[[dfg.distance.idxmin()]].s_rain.iloc[0] if (num > 0) else pd.NA,\n",
    "        'rain_closest_notna' : dfg.loc[[dfg.loc[~is_na, 'distance'].idxmin()]].s_rain.iloc[0] if (num_notna > 0) else pd.NA,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain = g.apply(rain_calc)\n",
    "station_rain = station_rain.join(circle_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain['consensus'] = np.where((station_rain.p >= (1-AGREEMENT_THRESHOLD)) & (station_rain.p <= AGREEMENT_THRESHOLD), \n",
    "                                     pd.NA, station_rain.p >= AGREEMENT_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the number of stations per circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain.num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(station_rain.num, kde=False).set_xlabel(\"number of stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the number of non-NaN stations per circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain.num_notna.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(station_rain.num_notna, kde=False).set_xlabel(\"number of non-NaN stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(station_rain.num, station_rain.num_notna/station_rain.num * 100).set_axis_labels(\"number of stations\", 'percent not NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### percent of circles where all stations are missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(station_rain.num_notna == 0).sum() / station_rain.size * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location, location, location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what percent of circles had the closest station as NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain.rain_closest.isna().sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what percent had the average value differ from the closest value (ignoring NaNs)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use kleene logical indexing to skip over NAs\n",
    "(station_rain.rain_closest_notna ^ station_rain.consensus).sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_obs.distance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(station_obs.distance, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall consensus of stations\n",
    "we use `4 * p(1-p)` to estiamte the \"disagreement\" amongst stations: this value ranges from `0` (all in agrement) to `1` (evenly split)  \n",
    "(here, `p` is the fraction of non-NaN stations that are `True` for rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"disagreement\" (4*p*(1-p)) by number of not NA\n",
    "# horizontal line is AGREEMENT_THRESHOLD, defined above\n",
    "p = sns.jointplot(station_rain.num_notna, 4 * station_rain.p * (1 - station_rain.p))\n",
    "p.set_axis_labels(\"number NaN\", '\"disgreement [4*p*(1-p)]\"')\n",
    "p.ax_joint.axhline(y = 4 * AGREEMENT_THRESHOLD * (1-AGREEMENT_THRESHOLD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"disagreement\" (4*p*(1-p)) by number of not NA\n",
    "# horizontal line is AGREEMENT_THRESHOLD, defined above\n",
    "p = sns.jointplot(station_rain.num_notna, 4 * station_rain.p * (1 - station_rain.p))\n",
    "p.set_axis_labels(\"number NaN\", '\"disgreement [4*p*(1-p)]\"')\n",
    "p.ax_joint.axhline(y = 4 * AGREEMENT_THRESHOLD * (1-AGREEMENT_THRESHOLD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what percent do not meet our dissagreement threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain.consensus.isna().sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain_na_circle_idx = station_rain.c_rain.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### percent of circles with missing rain observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rain_na_circle_idx.sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### percent of circles with both volunteer and all station data are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint\n",
    "(station_rain_na_circle_idx & (station_rain.num_notna == 0)).sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional \n",
    "(station_rain_na_circle_idx & (station_rain.num_notna == 0)).sum() / station_rain_na_circle_idx.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population\n",
    "(station_rain.num_notna == 0).sum() / station_rain.size * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, p, dof, expctd = stats.chi2_contingency(pd.crosstab(station_rain_na_circle_idx, station_rain.num_notna == 0))\n",
    "g, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the circle is missing data, it is much more likely that all other stations will too, when compared to the general population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### percent of circles with both volunteer and the closest station data are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint\n",
    "(station_rain_na_circle_idx & station_rain.rain_closest.isna()).sum()  / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional \n",
    "(station_rain_na_circle_idx & station_rain.rain_closest.isna()).sum() / station_rain_na_circle_idx.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population\n",
    "station_rain.rain_closest.isna().sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, p, dof, expctd = stats.chi2_contingency(pd.crosstab(station_rain_na_circle_idx, station_rain.rain_closest.isna()))\n",
    "g, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the circle is missing data, it is much **less** likely that the closes station will have missing data, when compared to the general population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of stations for circles with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actl = pd.crosstab(station_rain_na_circle_idx, station_rain.num_notna)\n",
    "g, p, dof, expctd = stats.chi2_contingency(actl)\n",
    "g, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(np.arange(expctd.shape[1]), actl.loc[True] - expctd[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it looks like the circle being missing implies that there is only one non-na station?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"disagreement\" (4*p*(1-p)) by number of not NA\n",
    "# horizontal line is AGREEMENT_THRESHOLD, defined above\n",
    "p = sns.jointplot(station_rain.loc[station_rain_na_circle_idx, 'num_notna'], \n",
    "                  4 * station_rain.loc[station_rain_na_circle_idx, 'p'] * (1 - station_rain.loc[station_rain_na_circle_idx, 'p']))\n",
    "p.ax_joint.scatter(station_rain.num_notna, 4 * station_rain.p * (1 - station_rain.p), color='pink', marker='x', alpha=0.5)\n",
    "p.set_axis_labels(\"number NaN\", '\"disgreement [4*p*(1-p)]\"')\n",
    "p.ax_joint.axhline(y = 4 * AGREEMENT_THRESHOLD * (1-AGREEMENT_THRESHOLD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what percent do not meet our dissagreement threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint\n",
    "station_rain.loc[station_rain_na_circle_idx, 'consensus'].isna().sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional\n",
    "station_rain.loc[station_rain_na_circle_idx, 'consensus'].isna().sum() / station_rain_na_circle_idx.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population\n",
    "station_rain.consensus.isna().sum() / len(station_rain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actl = pd.crosstab(station_rain_na_circle_idx, station_rain.consensus.isna())\n",
    "g, p, dof, expctd = stats.chi2_contingency(actl)\n",
    "g, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actl - expctd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing your rain data imples the stations are more likely to consense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on the closest station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actl = pd.crosstab(station_rain['rain_closest_notna'], station_rain['c_rain'])\n",
    "actl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition on volunteer data\n",
    "actl / actl.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total joint\n",
    "actl / actl.to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "actl.to_numpy().diagonal().sum() / actl.to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "pr = actl.loc[1,1] / actl.to_numpy()[[1,0], [1,1]].sum()\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "re = actl.loc[1,1] / actl.to_numpy()[[1,1], [1,0]].sum()\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1\n",
    "2 * pr * re / (pr + re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on the stations' consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actl = pd.crosstab(station_rain.consensus, station_rain['c_rain'])\n",
    "actl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition on volunteer data\n",
    "actl / actl.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total joint\n",
    "actl / actl.to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "actl.to_numpy().diagonal().sum() / actl.to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "pr = actl.loc[1,1] / actl.to_numpy()[[1,0], [1,1]].sum()\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "re = actl.loc[1,1] / actl.to_numpy()[[1,1], [1,0]].sum()\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1\n",
    "2 * pr * re / (pr + re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### did atleast one station aggree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actl = pd.crosstab(station_rain.num_true > 1, station_rain['c_rain'])\n",
    "actl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition on volunteer data\n",
    "actl / actl.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total joint\n",
    "actl / actl.to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "actl.to_numpy().diagonal().sum() / actl.to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "pr = actl.loc[1,1] / actl.to_numpy()[[1,0], [1,1]].sum()\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "re = actl.loc[1,1] / actl.to_numpy()[[1,1], [1,0]].sum()\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1\n",
    "2 * pr * re / (pr + re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audubon",
   "language": "python",
   "name": "audubon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
